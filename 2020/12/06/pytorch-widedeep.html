<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>pytorch-widedeep: deep learning for tabular data | infinitoml</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="pytorch-widedeep: deep learning for tabular data" />
<meta name="author" content="Javier Rodriguez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<meta property="og:description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<link rel="canonical" href="https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html" />
<meta property="og:url" content="https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html" />
<meta property="og:site_name" content="infinitoml" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-06T00:00:00-06:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Javier Rodriguez"},"description":"a flexible package to combine tabular data with text and images using wide and deep models.","@type":"BlogPosting","headline":"pytorch-widedeep: deep learning for tabular data","dateModified":"2020-12-06T00:00:00-06:00","datePublished":"2020-12-06T00:00:00-06:00","url":"https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/infinitoml/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jrzaurin.github.io/infinitoml/feed.xml" title="infinitoml" /><link rel="shortcut icon" type="image/x-icon" href="/infinitoml/images/infinitoml.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>pytorch-widedeep: deep learning for tabular data | infinitoml</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="pytorch-widedeep: deep learning for tabular data" />
<meta name="author" content="Javier Rodriguez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<meta property="og:description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<link rel="canonical" href="https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html" />
<meta property="og:url" content="https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html" />
<meta property="og:site_name" content="infinitoml" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-06T00:00:00-06:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Javier Rodriguez"},"description":"a flexible package to combine tabular data with text and images using wide and deep models.","@type":"BlogPosting","headline":"pytorch-widedeep: deep learning for tabular data","dateModified":"2020-12-06T00:00:00-06:00","datePublished":"2020-12-06T00:00:00-06:00","url":"https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://jrzaurin.github.io/infinitoml/2020/12/06/pytorch-widedeep.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://jrzaurin.github.io/infinitoml/feed.xml" title="infinitoml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/infinitoml/">infinitoml</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/infinitoml/about/">About Me</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">pytorch-widedeep: deep learning for tabular data</h1><p class="page-description">a flexible package to combine tabular data with text and images using wide and deep models.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-06T00:00:00-06:00" itemprop="datePublished">
        Dec 6, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Javier Rodriguez</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jrzaurin/infinitoml/tree/master/_notebooks/2020-12-06-pytorch-widedeep.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/infinitoml/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/jrzaurin/infinitoml/master?filepath=_notebooks%2F2020-12-06-pytorch-widedeep.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/infinitoml/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/jrzaurin/infinitoml/blob/master/_notebooks/2020-12-06-pytorch-widedeep.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/infinitoml/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#1.-Installation">1. Installation </a></li>
<li class="toc-entry toc-h2"><a href="#2.pytorch-widedeep--DL-Architectures">2.pytorch-widedeep  DL Architectures </a></li>
<li class="toc-entry toc-h2"><a href="# 3.-Quick-start"> 3. Quick start </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-06-pytorch-widedeep.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this post I describe the main components of the <code>Python</code> library <code>pytorch-widedeep</code>, which is intended to be a flexible package to use Deep Learning (hereafter DL) with tabular data and combine it with text and images via wide and deep models. <code>pytorch-widedeep</code> is based on Heng-Tze Cheng et al., 2016 <a href="https://arxiv.org/abs/1606.07792">paper</a>.</p>
<h2 id="1.-Installation">
<a class="anchor" href="#1.-Installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Installation<a class="anchor-link" href="#1.-Installation"> </a>
</h2>
<p>To install the package simply use pip:</p>
<div class="highlight"><pre><span></span>pip install pytorch-widedeep
</pre></div>
<p>or directly from github</p>
<div class="highlight"><pre><span></span>pip install git+https://github.com/jrzaurin/pytorch-widedeep.git
</pre></div>
<p><strong>Important note for Mac Users</strong></p>
<p>Note that the following comments are not directly related to the package, but to the interplay between <code>pytorch</code> and OSX (more precisely <code>pytorch</code>'s dependency on <code>OpenMP</code> I believe) and in general parallel processing in Mac.</p>
<p>In the first place, at the time of writing the latest <code>pytorch</code> version is <code>1.7</code>. This version is known to have some <a href="https://stackoverflow.com/questions/64772335/pytorch-w-parallelnative-cpp206">issues</a> when running on Mac and the data-loaders might not run in parallel. On the other hand, since <code>Python 3.8</code> the <code>multiprocessing</code> library start method changed from <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods">'fork' to 'spawn'</a>. This also affects the data-loaders (for any torch version) and they will not run in parallel.</p>
<p>Therefore, for Mac users I suggest using <code>python 3.7</code> and <code>torch &lt;= 1.6</code> (with its corresponding <code>torchvision</code> version, i.e. <code>&lt;= 0.7.0</code>). I could have enforced this versioning via the <code>setup.py</code> file. However, there are a number of unknowns and I preferred to leave it as it is. For example I developed the package using macOS Catalina and maybe some of this issues are not present in the new release Big Sur. Also, I hope that they release soon a patch for <code>pytorch 1.7</code> and some, if not all these problems disappear.</p>
<p>Installing <code>pytorch-widedeep</code> via <code>pip</code> will install the latest version. Therefore, if these problems are present and the dataloaders do not run in parallel, one can easily downgrade manually:</p>
<div class="highlight"><pre><span></span>pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.6.0 <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.7.0
</pre></div>
<p><em>None of these issues affect Linux users</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.pytorch-widedeep--DL-Architectures">
<a class="anchor" href="#2.pytorch-widedeep--DL-Architectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.<code>pytorch-widedeep</code>  DL Architectures<a class="anchor-link" href="#2.pytorch-widedeep--DL-Architectures"> </a>
</h2>
<p>As I mentioned earlier <code>pytorch-widedeep</code> combines tabular data with text and images via wide and deep models. With that in mind, the two main architectures one can build with a few lines of code using <code>pytorch-widedeep</code> are:</p>
<p align="center">
  <img width="700" src="figures/pytorch-widedeep/arch_1.png">
</p>
<p><strong>Architecture 1</strong>: architecture 1 combines the <code>Wide</code>, linear model with the outputs from the <code>DeepDense</code> or <code>DeepDenseResnet</code>, <code>DeepText</code> and <code>DeepImage</code> components connected to a final output neuron or neurons, depending on whether we are performing a binary classification or regression, or a multi-class classification. The components within the faded-pink rectangles are concatenated. Later in the post I will describe in detail each of the components, for now, let's just move on.</p>
<p>In math terms, and following the notation in the <a href="https://arxiv.org/abs/1606.07792">paper</a>, Architecture 1 can be formulated as:</p>
<p align="center">
  <img width="500" src="figures/pytorch-widedeep/architecture_1_math.png">
</p>
<p>Where $W$ are the weight matrices applied to the wide model and to the final activations of the deep models, '$a$' are these final activations, and $\phi(x)$ are the cross product transformations of the original features '$x$'. In case you are wondering what are <em>"cross product transformations"</em>, here is a quote taken directly from the paper: <em>"For binary features, a cross-product transformation (e.g., “AND(gender=female, language=en)”) is 1 if and only if the constituent features (“gender=female” and “language=en”) are all 1, and 0 otherwise"</em>.</p>
<p align="center">
  <img width="700" src="figures/pytorch-widedeep/arch_2.png">
</p>
<p><strong>Architecture 2</strong>: architecture 2 combines the <code>Wide</code>, linear model with the <code>Deep</code> components of the model connected to the output neuron(s), after the different Deep components have been themselves combined through a FC-Head (that I refer as <code>DeepHead</code>).</p>
<p>In math terms, and following the notation in the <a href="https://arxiv.org/abs/1606.07792">paper</a>, Architecture 2 can be formulated as:</p>
<p align="center">
  <img width="300" src="figures/pytorch-widedeep/architecture_2_math.png">
</p>
<p>Is imporrtant to metion that each individual component, <code>wide</code>, <code>deepdense</code> (either <code>DeepDense</code> or <code>DeepDenseResnet</code>), <code>deeptext</code> and <code>deepimage</code>, can be used independently and in isolation. For example, one could use only <code>wide</code>, which is in simply a linear model. Or use <code>DeepDense</code> which is in essence a similar implementation to that of the <a href="https://docs.fast.ai/tabular.learner">Tabular</a> API in the fastai library (which I strongly recommend).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id=" 3.-Quick-start">
<a class="anchor" href="#%C2%A03.-Quick-start" aria-hidden="true"><span class="octicon octicon-link"></span></a> 3. Quick start<a class="anchor-link" href="#%C2%A03.-Quick-start"> </a>
</h2>
<p>Before diving into the details of the library let's just say that you just want to quickly run one example and get the feel of how <code>pytorch-widedeep</code> works. Let go through a quick example using the adult census dataset. In this example we will be fitting a model comprised by a <code>Wide</code> and <code>DeepDense</code> components</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="n">adult</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"data/adult/adult.csv.zip"</span><span class="p">)</span>
<span class="n">adult</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"-"</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">adult</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">adult</span><span class="p">[</span><span class="s2">"income_label"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">adult</span><span class="p">[</span><span class="s2">"income"</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">"&gt;50K"</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">adult</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">"income"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">adult</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">'O'</span><span class="p">:</span>
        <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">"unknown"</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">"?"</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">adult</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>educational_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>gender</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>income_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>25</td>
      <td>private</td>
      <td>226802</td>
      <td>11th</td>
      <td>7</td>
      <td>never-married</td>
      <td>machine-op-inspct</td>
      <td>own-child</td>
      <td>black</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38</td>
      <td>private</td>
      <td>89814</td>
      <td>hs-grad</td>
      <td>9</td>
      <td>married-civ-spouse</td>
      <td>farming-fishing</td>
      <td>husband</td>
      <td>white</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>50</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>local-gov</td>
      <td>336951</td>
      <td>assoc-acdm</td>
      <td>12</td>
      <td>married-civ-spouse</td>
      <td>protective-serv</td>
      <td>husband</td>
      <td>white</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44</td>
      <td>private</td>
      <td>160323</td>
      <td>some-college</td>
      <td>10</td>
      <td>married-civ-spouse</td>
      <td>machine-op-inspct</td>
      <td>husband</td>
      <td>black</td>
      <td>male</td>
      <td>7688</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>18</td>
      <td>unknown</td>
      <td>103497</td>
      <td>some-college</td>
      <td>10</td>
      <td>never-married</td>
      <td>unknown</td>
      <td>own-child</td>
      <td>white</td>
      <td>female</td>
      <td>0</td>
      <td>0</td>
      <td>30</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_widedeep.preprocessing</span> <span class="kn">import</span> <span class="n">WidePreprocessor</span><span class="p">,</span> <span class="n">DensePreprocessor</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.models</span> <span class="kn">import</span> <span class="n">Wide</span><span class="p">,</span> <span class="n">DeepDense</span><span class="p">,</span> <span class="n">WideDeep</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>

<span class="n">adult_train</span><span class="p">,</span> <span class="n">adult_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">adult</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">adult</span><span class="o">.</span><span class="n">income_label</span><span class="p">)</span>

<span class="c1"># prepare wide, crossed, embedding and continuous columns and target</span>
<span class="n">wide_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"education"</span><span class="p">,</span> <span class="s2">"relationship"</span><span class="p">,</span> <span class="s2">"workclass"</span><span class="p">,</span> <span class="s2">"occupation"</span><span class="p">,</span> <span class="s2">"native_country"</span><span class="p">,</span> <span class="s2">"gender"</span><span class="p">]</span>
<span class="n">cross_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"education"</span><span class="p">,</span> <span class="s2">"occupation"</span><span class="p">),</span> <span class="p">(</span><span class="s2">"native_country"</span><span class="p">,</span> <span class="s2">"occupation"</span><span class="p">)]</span>
<span class="n">embed_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">"education"</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="s2">"workclass"</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="s2">"occupation"</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="s2">"native_country"</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">cont_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"age"</span><span class="p">,</span> <span class="s2">"hours_per_week"</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">adult_train</span><span class="p">[</span><span class="s2">"income_label"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># wide component</span>
<span class="n">preprocess_wide</span> <span class="o">=</span> <span class="n">WidePreprocessor</span><span class="p">(</span><span class="n">wide_cols</span><span class="o">=</span><span class="n">wide_cols</span><span class="p">,</span> <span class="n">crossed_cols</span><span class="o">=</span><span class="n">cross_cols</span><span class="p">)</span>
<span class="n">X_wide</span> <span class="o">=</span> <span class="n">preprocess_wide</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">adult_train</span><span class="p">)</span>
<span class="n">wide</span> <span class="o">=</span> <span class="n">Wide</span><span class="p">(</span><span class="n">wide_dim</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_wide</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># deepdense component</span>
<span class="n">preprocess_deep</span> <span class="o">=</span> <span class="n">DensePreprocessor</span><span class="p">(</span><span class="n">embed_cols</span><span class="o">=</span><span class="n">embed_cols</span><span class="p">,</span> <span class="n">continuous_cols</span><span class="o">=</span><span class="n">cont_cols</span><span class="p">)</span>
<span class="n">X_deep</span> <span class="o">=</span> <span class="n">preprocess_deep</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">adult_train</span><span class="p">)</span>
<span class="n">deepdense</span> <span class="o">=</span> <span class="n">DeepDense</span><span class="p">(</span><span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">deep_column_idx</span><span class="o">=</span><span class="n">preprocess_deep</span><span class="o">.</span><span class="n">deep_column_idx</span><span class="p">,</span> 
                      <span class="n">embed_input</span><span class="o">=</span><span class="n">preprocess_deep</span><span class="o">.</span><span class="n">embeddings_input</span><span class="p">,</span> <span class="n">continuous_cols</span><span class="o">=</span><span class="n">cont_cols</span><span class="p">)</span>

<span class="c1"># build, compile and fit</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WideDeep</span><span class="p">(</span><span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">,</span> <span class="n">deepdense</span><span class="o">=</span><span class="n">deepdense</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">"binary"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">Accuracy</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide</span><span class="p">,</span> <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> 

<span class="c1"># predict</span>
<span class="n">X_wide_te</span> <span class="o">=</span> <span class="n">preprocess_wide</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">adult_test</span><span class="p">)</span>
<span class="n">X_deep_te</span> <span class="o">=</span> <span class="n">preprocess_deep</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">adult_test</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide_te</span><span class="p">,</span> <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep_te</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 0/153 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 153/153 [00:02&lt;00:00, 52.44it/s, loss=0.526, metrics={'acc': 0.7471}]
epoch 2: 100%|██████████| 153/153 [00:02&lt;00:00, 57.72it/s, loss=0.409, metrics={'acc': 0.8116}]
predict: 100%|██████████| 39/39 [00:00&lt;00:00, 196.34it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="jrzaurin/infinitoml"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/infinitoml/2020/12/06/pytorch-widedeep.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/infinitoml/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/infinitoml/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/infinitoml/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>limitless or endless in space, extent, or size; impossible to measure or calculate.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jrzaurin" title="jrzaurin"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/javier-rodriguez-zaurin-06277454" title="javier-rodriguez-zaurin-06277454"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/jrzaurin" title="jrzaurin"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
