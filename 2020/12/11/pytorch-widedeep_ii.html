<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>pytorch-widedeep, deep learning for tabular data II: advanced use | infinitoml</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="pytorch-widedeep, deep learning for tabular data II: advanced use" />
<meta name="author" content="Javier Rodriguez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<meta property="og:description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<link rel="canonical" href="https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html" />
<meta property="og:url" content="https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html" />
<meta property="og:site_name" content="infinitoml" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-11T00:00:00-06:00" />
<script type="application/ld+json">
{"dateModified":"2020-12-11T00:00:00-06:00","datePublished":"2020-12-11T00:00:00-06:00","author":{"@type":"Person","name":"Javier Rodriguez"},"description":"a flexible package to combine tabular data with text and images using wide and deep models.","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html"},"url":"https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html","headline":"pytorch-widedeep, deep learning for tabular data II: advanced use","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/infinitoml/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jrzaurin.github.io/infinitoml/feed.xml" title="infinitoml" /><link rel="shortcut icon" type="image/x-icon" href="/infinitoml/images/infinitoml.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>pytorch-widedeep, deep learning for tabular data II: advanced use | infinitoml</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="pytorch-widedeep, deep learning for tabular data II: advanced use" />
<meta name="author" content="Javier Rodriguez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<meta property="og:description" content="a flexible package to combine tabular data with text and images using wide and deep models." />
<link rel="canonical" href="https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html" />
<meta property="og:url" content="https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html" />
<meta property="og:site_name" content="infinitoml" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-11T00:00:00-06:00" />
<script type="application/ld+json">
{"dateModified":"2020-12-11T00:00:00-06:00","datePublished":"2020-12-11T00:00:00-06:00","author":{"@type":"Person","name":"Javier Rodriguez"},"description":"a flexible package to combine tabular data with text and images using wide and deep models.","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html"},"url":"https://jrzaurin.github.io/infinitoml/2020/12/11/pytorch-widedeep_ii.html","headline":"pytorch-widedeep, deep learning for tabular data II: advanced use","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://jrzaurin.github.io/infinitoml/feed.xml" title="infinitoml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/infinitoml/">infinitoml</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/infinitoml/about/">About Me</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">pytorch-widedeep, deep learning for tabular data II: advanced use</h1><p class="page-description">a flexible package to combine tabular data with text and images using wide and deep models.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-11T00:00:00-06:00" itemprop="datePublished">
        Dec 11, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Javier Rodriguez</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      22 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jrzaurin/infinitoml/tree/master/_notebooks/2020-12-11-pytorch-widedeep_ii.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/infinitoml/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/jrzaurin/infinitoml/master?filepath=_notebooks%2F2020-12-11-pytorch-widedeep_ii.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/infinitoml/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/jrzaurin/infinitoml/blob/master/_notebooks/2020-12-11-pytorch-widedeep_ii.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/infinitoml/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#1.-Binary-classification-with-varying-parameters">1. Binary classification with varying parameters </a></li>
<li class="toc-entry toc-h2"><a href="#2.-Regression-combining-tabular,-text-and-images">2. Regression combining tabular, text and images </a></li>
<li class="toc-entry toc-h2"><a href="#3.-Warm-up-routines">3. Warm up routines </a>
<ul>
<li class="toc-entry toc-h3"><a href="#3.1-The-Felbo-warm-up-routine">3.1 The Felbo warm-up routine </a></li>
<li class="toc-entry toc-h3"><a href="#3.1-The-Howard-warm-up-routine">3.1 The Howard warm-up routine </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#4.-Custom-model">4. Custom model </a></li>
<li class="toc-entry toc-h2"><a href="#5.-Conclusion">5. Conclusion </a>
<ul>
<li class="toc-entry toc-h4"><a href="#References">References </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-11-pytorch-widedeep_ii.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Binary-classification-with-varying-parameters">
<a class="anchor" href="#1.-Binary-classification-with-varying-parameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Binary classification with varying parameters<a class="anchor-link" href="#1.-Binary-classification-with-varying-parameters"> </a>
</h2>
<p>Let's start by using again the <a href="http://archive.ics.uci.edu/ml/datasets/Adult">adult census</a> dataset.</p>
<p>Before moving any further, let me emphasize that, as we go through the examples, one should not pay excessive (or any) attention to the loss or the metrics in the sense that the input parameters are not selected to obtain "state of the art", but to illustrate usability.</p>
<p>A proper benchmarking exercise will be carried out in a future post. Having said that, and without further ado, let's start.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">adult</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"data/adult/adult.csv.zip"</span><span class="p">)</span>
<span class="n">adult</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"-"</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">adult</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">adult</span><span class="p">[</span><span class="s2">"income_label"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">adult</span><span class="p">[</span><span class="s2">"income"</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">"&gt;50K"</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">adult</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">"income"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">adult</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">'O'</span><span class="p">:</span>
        <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">"unknown"</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">"?"</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">adult</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">adult</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>educational_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>gender</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>income_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>25</td>
      <td>private</td>
      <td>226802</td>
      <td>11th</td>
      <td>7</td>
      <td>never-married</td>
      <td>machine-op-inspct</td>
      <td>own-child</td>
      <td>black</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38</td>
      <td>private</td>
      <td>89814</td>
      <td>hs-grad</td>
      <td>9</td>
      <td>married-civ-spouse</td>
      <td>farming-fishing</td>
      <td>husband</td>
      <td>white</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>50</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>local-gov</td>
      <td>336951</td>
      <td>assoc-acdm</td>
      <td>12</td>
      <td>married-civ-spouse</td>
      <td>protective-serv</td>
      <td>husband</td>
      <td>white</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44</td>
      <td>private</td>
      <td>160323</td>
      <td>some-college</td>
      <td>10</td>
      <td>married-civ-spouse</td>
      <td>machine-op-inspct</td>
      <td>husband</td>
      <td>black</td>
      <td>male</td>
      <td>7688</td>
      <td>0</td>
      <td>40</td>
      <td>united-states</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>18</td>
      <td>unknown</td>
      <td>103497</td>
      <td>some-college</td>
      <td>10</td>
      <td>never-married</td>
      <td>unknown</td>
      <td>own-child</td>
      <td>white</td>
      <td>female</td>
      <td>0</td>
      <td>0</td>
      <td>30</td>
      <td>united-states</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>if you read the first post you will be familiar with the code below:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">pytorch_widedeep.preprocessing</span> <span class="kn">import</span> <span class="n">WidePreprocessor</span><span class="p">,</span> <span class="n">DensePreprocessor</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.initializers</span> <span class="kn">import</span> <span class="n">KaimingNormal</span><span class="p">,</span> <span class="n">XavierNormal</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">LRHistory</span><span class="p">,</span> <span class="n">EarlyStopping</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span><span class="p">,</span> <span class="n">Recall</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.optim</span> <span class="kn">import</span> <span class="n">RAdam</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.models</span> <span class="kn">import</span> <span class="n">Wide</span><span class="p">,</span> <span class="n">DeepDense</span><span class="p">,</span> <span class="n">WideDeep</span>

<span class="n">wide_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'education'</span><span class="p">,</span> <span class="s1">'relationship'</span><span class="p">,</span><span class="s1">'workclass'</span><span class="p">,</span><span class="s1">'occupation'</span><span class="p">,</span><span class="s1">'native_country'</span><span class="p">,</span><span class="s1">'gender'</span><span class="p">]</span>
<span class="n">crossed_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">'education'</span><span class="p">,</span> <span class="s1">'occupation'</span><span class="p">),</span> <span class="p">(</span><span class="s1">'native_country'</span><span class="p">,</span> <span class="s1">'occupation'</span><span class="p">)]</span>
<span class="n">cat_embed_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">'education'</span><span class="p">,</span><span class="mi">16</span><span class="p">),</span> <span class="p">(</span><span class="s1">'relationship'</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="s1">'workclass'</span><span class="p">,</span><span class="mi">16</span><span class="p">),</span> <span class="p">(</span><span class="s1">'occupation'</span><span class="p">,</span><span class="mi">16</span><span class="p">),(</span><span class="s1">'native_country'</span><span class="p">,</span><span class="mi">16</span><span class="p">)]</span>
<span class="n">continuous_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"age"</span><span class="p">,</span><span class="s2">"hours_per_week"</span><span class="p">]</span>
<span class="n">target_col</span> <span class="o">=</span> <span class="s1">'income_label'</span>

<span class="c1"># TARGET</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">adult</span><span class="p">[</span><span class="n">target_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># WIDE</span>
<span class="n">preprocess_wide</span> <span class="o">=</span> <span class="n">WidePreprocessor</span><span class="p">(</span><span class="n">wide_cols</span><span class="o">=</span><span class="n">wide_cols</span><span class="p">,</span> <span class="n">crossed_cols</span><span class="o">=</span><span class="n">crossed_cols</span><span class="p">)</span>
<span class="n">X_wide</span> <span class="o">=</span> <span class="n">preprocess_wide</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">adult</span><span class="p">)</span>

<span class="c1"># DEEP</span>
<span class="n">preprocess_deep</span> <span class="o">=</span> <span class="n">DensePreprocessor</span><span class="p">(</span><span class="n">embed_cols</span><span class="o">=</span><span class="n">cat_embed_cols</span><span class="p">,</span> <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">)</span>
<span class="n">X_deep</span> <span class="o">=</span> <span class="n">preprocess_deep</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">adult</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wide</span> <span class="o">=</span> <span class="n">Wide</span><span class="p">(</span><span class="n">wide_dim</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_wide</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># We can add dropout and batchnorm to the dense layers</span>
<span class="n">deepdense</span> <span class="o">=</span> <span class="n">DeepDense</span><span class="p">(</span><span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">deep_column_idx</span><span class="o">=</span><span class="n">preprocess_deep</span><span class="o">.</span><span class="n">deep_column_idx</span><span class="p">,</span>
                      <span class="n">embed_input</span><span class="o">=</span><span class="n">preprocess_deep</span><span class="o">.</span><span class="n">embeddings_input</span><span class="p">,</span>
                      <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">WideDeep</span><span class="p">(</span><span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">,</span> <span class="n">deepdense</span><span class="o">=</span><span class="n">deepdense</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's have a look to the model that we will be running:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>WideDeep(
  (wide): Wide(
    (wide_linear): Embedding(797, 1, padding_idx=0)
  )
  (deepdense): Sequential(
    (0): DeepDense(
      (embed_layers): ModuleDict(
        (emb_layer_education): Embedding(17, 16)
        (emb_layer_native_country): Embedding(43, 16)
        (emb_layer_occupation): Embedding(16, 16)
        (emb_layer_relationship): Embedding(7, 8)
        (emb_layer_workclass): Embedding(10, 16)
      )
      (embed_dropout): Dropout(p=0.0, inplace=False)
      (dense): Sequential(
        (dense_layer_0): Sequential(
          (0): Linear(in_features=74, out_features=64, bias=True)
          (1): LeakyReLU(negative_slope=0.01, inplace=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Dropout(p=0.5, inplace=False)
        )
        (dense_layer_1): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): LeakyReLU(negative_slope=0.01, inplace=True)
          (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we will define the set up for each model component, including optimizers, learning rate schedulers and initializers:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Optimizers</span>
<span class="n">wide_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wide</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">deep_opt</span> <span class="o">=</span> <span class="n">RAdam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deepdense</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># LR Schedulers</span>
<span class="n">wide_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">wide_opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">deep_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">deep_opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Component-dependent settings as Dict</span>
<span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">wide_opt</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">deep_opt</span><span class="p">}</span>
<span class="n">schedulers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">wide_sch</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">deep_sch</span><span class="p">}</span>
<span class="n">initializers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">KaimingNormal</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">XavierNormal</span><span class="p">}</span>

<span class="c1"># General settings as List</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">LRHistory</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">'model_weights/wd_out'</span><span class="p">)]</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Recall</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Compile and fit!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">'binary'</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">,</span> <span class="n">lr_schedulers</span><span class="o">=</span><span class="n">schedulers</span><span class="p">,</span> 
              <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> 
              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide</span><span class="p">,</span> <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">val_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s1">'train_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"train"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"val"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"n epochs"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Loss"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s1">'train_acc'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"train"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s1">'val_acc'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"val"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"n epochs"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Accuracy"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">lr_history</span><span class="p">[</span><span class="s1">'lr_wide_0'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"wide"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">lr_history</span><span class="p">[</span><span class="s1">'lr_deepdense_0'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"deepdense"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"n epochs"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"learning rate"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0, 0.5, 'learning rate')</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see from the plots, the learning rate effectively decreases by a factor of 0.1 (the default) after the corresponding <code>step_size</code> for each component. Note that the keys in the <code>model.lr_history</code> dictionary have a suffix <code>_0</code>. This is because if you pass different parameter groups to the torch optimizers, these will also be recorded. We'll see this in the regression example, in the next section.</p>
<p>Before I move to the next section let me just mention that the <code>WideDeep</code> class comes with a useful method to "rescue" the learned embeddings, very creatively called <code>get_embeddings</code>. For example, let's say I want to use the embeddings learned for the different levels of the categorical feature <code>education</code>. These can be access via:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">education_embed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_embeddings</span><span class="p">(</span>
    <span class="n">col_name</span><span class="o">=</span><span class="s1">'education'</span><span class="p">,</span> 
    <span class="n">cat_encoding_dict</span><span class="o">=</span><span class="n">preprocess_deep</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">encoding_dict</span>
<span class="p">)</span>
<span class="n">education_embed</span><span class="p">[</span><span class="s1">'doctorate'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([ 0.23485082,  0.41219023,  0.12688892,  0.08351105, -0.29780635,
       -0.5321735 , -0.24137467, -0.49889308,  0.37074092, -0.11963069,
        0.7072009 ,  0.5613647 , -0.0930844 , -0.5126964 , -0.05072869,
       -0.40419328], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Regression-combining-tabular,-text-and-images">
<a class="anchor" href="#2.-Regression-combining-tabular,-text-and-images" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Regression combining tabular, text and images<a class="anchor-link" href="#2.-Regression-combining-tabular,-text-and-images"> </a>
</h2>
<p>For this example we will use a small sample (so you can run it locally in a laptop) of the <a href="http://insideairbnb.com/get-the-data.html">Airbnb listings dataset</a> in London.</p>
<p>In case you are interested in all details, I did prepared the original dataset for this post, and all the code can be found at the <code>airbnb_data_preprocessing.py</code>, <a href="%60https://github.com/jrzaurin/pytorch-widedeep/blob/master/examples/airbnb_data_preprocessing.py%60">here</a>. After such preprocessing the data looks like this:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="n">airbnb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/airbnb/airbnb_sample.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">airbnb</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>host_id</th>
      <th>description</th>
      <th>host_listings_count</th>
      <th>host_identity_verified</th>
      <th>neighbourhood_cleansed</th>
      <th>latitude</th>
      <th>longitude</th>
      <th>is_location_exact</th>
      <th>property_type</th>
      <th>room_type</th>
      <th>accommodates</th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>beds</th>
      <th>guests_included</th>
      <th>minimum_nights</th>
      <th>instant_bookable</th>
      <th>cancellation_policy</th>
      <th>has_house_rules</th>
      <th>host_gender</th>
      <th>accommodates_catg</th>
      <th>guests_included_catg</th>
      <th>minimum_nights_catg</th>
      <th>host_listings_count_catg</th>
      <th>bathrooms_catg</th>
      <th>bedrooms_catg</th>
      <th>beds_catg</th>
      <th>amenity_24-hour_check-in</th>
      <th>amenity__toilet</th>
      <th>amenity_accessible-height_bed</th>
      <th>amenity_accessible-height_toilet</th>
      <th>amenity_air_conditioning</th>
      <th>amenity_air_purifier</th>
      <th>amenity_alfresco_bathtub</th>
      <th>amenity_amazon_echo</th>
      <th>amenity_baby_bath</th>
      <th>amenity_baby_monitor</th>
      <th>amenity_babysitter_recommendations</th>
      <th>amenity_balcony</th>
      <th>amenity_bath_towel</th>
      <th>amenity_bathroom_essentials</th>
      <th>amenity_bathtub</th>
      <th>amenity_bathtub_with_bath_chair</th>
      <th>amenity_bbq_grill</th>
      <th>amenity_beach_essentials</th>
      <th>amenity_beach_view</th>
      <th>amenity_beachfront</th>
      <th>amenity_bed_linens</th>
      <th>amenity_bedroom_comforts</th>
      <th>...</th>
      <th>amenity_roll-in_shower</th>
      <th>amenity_room-darkening_shades</th>
      <th>amenity_safety_card</th>
      <th>amenity_sauna</th>
      <th>amenity_self_check-in</th>
      <th>amenity_shampoo</th>
      <th>amenity_shared_gym</th>
      <th>amenity_shared_hot_tub</th>
      <th>amenity_shared_pool</th>
      <th>amenity_shower_chair</th>
      <th>amenity_single_level_home</th>
      <th>amenity_ski-in_ski-out</th>
      <th>amenity_smart_lock</th>
      <th>amenity_smart_tv</th>
      <th>amenity_smoke_detector</th>
      <th>amenity_smoking_allowed</th>
      <th>amenity_soaking_tub</th>
      <th>amenity_sound_system</th>
      <th>amenity_stair_gates</th>
      <th>amenity_stand_alone_steam_shower</th>
      <th>amenity_standing_valet</th>
      <th>amenity_steam_oven</th>
      <th>amenity_stove</th>
      <th>amenity_suitable_for_events</th>
      <th>amenity_sun_loungers</th>
      <th>amenity_table_corner_guards</th>
      <th>amenity_tennis_court</th>
      <th>amenity_terrace</th>
      <th>amenity_toilet_paper</th>
      <th>amenity_touchless_faucets</th>
      <th>amenity_tv</th>
      <th>amenity_walk-in_shower</th>
      <th>amenity_warming_drawer</th>
      <th>amenity_washer</th>
      <th>amenity_washer_dryer</th>
      <th>amenity_waterfront</th>
      <th>amenity_well-lit_path_to_entrance</th>
      <th>amenity_wheelchair_accessible</th>
      <th>amenity_wide_clearance_to_shower</th>
      <th>amenity_wide_doorway_to_guest_bathroom</th>
      <th>amenity_wide_entrance</th>
      <th>amenity_wide_entrance_for_guests</th>
      <th>amenity_wide_entryway</th>
      <th>amenity_wide_hallways</th>
      <th>amenity_wifi</th>
      <th>amenity_window_guards</th>
      <th>amenity_wine_cooler</th>
      <th>security_deposit</th>
      <th>extra_people</th>
      <th>yield</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13913.jpg</td>
      <td>54730</td>
      <td>My bright double bedroom with a large window has a relaxed feeling! It comfortably fits one or t...</td>
      <td>4.0</td>
      <td>f</td>
      <td>Islington</td>
      <td>51.56802</td>
      <td>-0.11121</td>
      <td>t</td>
      <td>apartment</td>
      <td>private_room</td>
      <td>2</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1</td>
      <td>1</td>
      <td>f</td>
      <td>moderate</td>
      <td>1</td>
      <td>female</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>100.0</td>
      <td>15.0</td>
      <td>12.0</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 223 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define what will go through the wide and deep components</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># wide</span>
<span class="n">crossed_cols</span> <span class="o">=</span> <span class="p">([</span><span class="s2">"property_type"</span><span class="p">,</span> <span class="s2">"room_type"</span><span class="p">],)</span>
<span class="n">already_dummies</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">airbnb</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s2">"amenity"</span> <span class="ow">in</span> <span class="n">c</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">"has_house_rules"</span><span class="p">]</span>
<span class="n">wide_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"is_location_exact"</span><span class="p">,</span>
    <span class="s2">"property_type"</span><span class="p">,</span>
    <span class="s2">"room_type"</span><span class="p">,</span>
    <span class="s2">"host_gender"</span><span class="p">,</span>
    <span class="s2">"instant_bookable"</span><span class="p">,</span>
<span class="p">]</span> <span class="o">+</span> <span class="n">already_dummies</span>

<span class="c1"># deepdense</span>
<span class="n">cat_embed_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="n">c</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">airbnb</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s2">"catg"</span> <span class="ow">in</span> <span class="n">c</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"neighbourhood_cleansed"</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"cancellation_policy"</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">continuous_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"latitude"</span><span class="p">,</span> <span class="s2">"longitude"</span><span class="p">,</span> <span class="s2">"security_deposit"</span><span class="p">,</span> <span class="s2">"extra_people"</span><span class="p">]</span>
<span class="n">already_standard</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"latitude"</span><span class="p">,</span> <span class="s2">"longitude"</span><span class="p">]</span>

<span class="c1"># deeptext (at this day and age you might want to use other word vectors...)</span>
<span class="n">text_col</span> <span class="o">=</span> <span class="s2">"description"</span>
<span class="n">word_vectors_path</span> <span class="o">=</span> <span class="s2">"data/glove.6B/glove.6B.100d.txt"</span>

<span class="c1"># deepimage</span>
<span class="n">img_col</span> <span class="o">=</span> <span class="s2">"id"</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="s2">"data/airbnb/property_picture"</span>

<span class="c1"># target</span>
<span class="n">target_col</span> <span class="o">=</span> <span class="s2">"yield"</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note the following: columns that are already dummies (defined as <code>already_dummies</code>), are treated as any other wide column. Internally, nothing will really happen to them. They will just add one entry to the embedding lookup table.</p>
<p>On the other hand, you will see that among the columns that will be passed through the <code>deepdense</code> component we have <code>already_standard</code> columns, which are longitude and latitude. These are columns for which it makes no sense to standardize them. However, at the same time, one would not advise to pass inputs to the network that are in a very different scale. Nonetheless, I decided to include a <code>already_standard</code> parameter in the <code>DensePreprocessor</code> and the columns passed as <code>already_standard</code> will not be normalized.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">pytorch_widedeep.preprocessing</span> <span class="kn">import</span> <span class="n">WidePreprocessor</span><span class="p">,</span> <span class="n">DensePreprocessor</span><span class="p">,</span> <span class="n">TextPreprocessor</span><span class="p">,</span> <span class="n">ImagePreprocessor</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.models</span> <span class="kn">import</span> <span class="n">Wide</span><span class="p">,</span> <span class="n">DeepDense</span><span class="p">,</span> <span class="n">DeepText</span><span class="p">,</span> <span class="n">DeepImage</span><span class="p">,</span> <span class="n">WideDeep</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.initializers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pytorch_widedeep.callbacks</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="n">airbnb</span><span class="p">[</span><span class="n">target_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">wide_preprocessor</span> <span class="o">=</span> <span class="n">WidePreprocessor</span><span class="p">(</span><span class="n">wide_cols</span><span class="o">=</span><span class="n">wide_cols</span><span class="p">,</span> <span class="n">crossed_cols</span><span class="o">=</span><span class="n">crossed_cols</span><span class="p">)</span>
<span class="n">X_wide</span> <span class="o">=</span> <span class="n">wide_preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">airbnb</span><span class="p">)</span>

<span class="n">deep_preprocessor</span> <span class="o">=</span> <span class="n">DensePreprocessor</span><span class="p">(</span><span class="n">embed_cols</span><span class="o">=</span><span class="n">cat_embed_cols</span><span class="p">,</span> <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">,</span>
    <span class="n">already_standard</span><span class="o">=</span><span class="n">already_standard</span><span class="p">)</span>
<span class="n">X_deep</span> <span class="o">=</span> <span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">airbnb</span><span class="p">)</span>

<span class="n">text_preprocessor</span> <span class="o">=</span> <span class="n">TextPreprocessor</span><span class="p">(</span><span class="n">word_vectors_path</span><span class="o">=</span><span class="n">word_vectors_path</span><span class="p">,</span> <span class="n">text_col</span><span class="o">=</span><span class="n">text_col</span><span class="p">)</span>
<span class="n">X_text</span> <span class="o">=</span> <span class="n">text_preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">airbnb</span><span class="p">)</span>

<span class="n">image_preprocessor</span> <span class="o">=</span> <span class="n">ImagePreprocessor</span><span class="p">(</span><span class="n">img_col</span><span class="o">=</span><span class="n">img_col</span><span class="p">,</span> <span class="n">img_path</span><span class="o">=</span><span class="n">img_path</span><span class="p">)</span>
<span class="n">X_images</span> <span class="o">=</span> <span class="n">image_preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">airbnb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The vocabulary contains 2192 tokens
Indexing word vectors...
Loaded 400000 word vectors
Preparing embeddings matrix...
2175 words in the vocabulary had data/glove.6B/glove.6B.100d.txt vectors and appear more than 5 times
Reading Images from data/airbnb/property_picture
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  4%|▍         | 40/1001 [00:00&lt;00:02, 395.94it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Resizing
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1001/1001 [00:02&lt;00:00, 392.30it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Computing normalisation metrics
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this stage the data is ready to be passed through the model. However, instead of building a "simple" model that collects the <code>wide</code>, <code>deepdense</code>, <code>deeptext</code> and <code>deepimage</code> component, I am going to use this opportunity to illustrate <code>pytorch-widedepp</code>'s flexibility to build wide and deep models. I like to call this, getting into <em>Kaggle mode</em>.</p>
<p>First we define the components of the model...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wide</span> <span class="o">=</span> <span class="n">Wide</span><span class="p">(</span><span class="n">wide_dim</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_wide</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">deepdense</span> <span class="o">=</span> <span class="n">DeepDense</span><span class="p">(</span><span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">64</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> 
                      <span class="n">deep_column_idx</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">deep_column_idx</span><span class="p">,</span>
                      <span class="n">embed_input</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">embeddings_input</span><span class="p">,</span>
                      <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">)</span>

<span class="n">deeptext</span> <span class="o">=</span> <span class="n">DeepText</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">text_preprocessor</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                    <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">rnn_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                    <span class="n">embedding_matrix</span><span class="o">=</span><span class="n">text_preprocessor</span><span class="o">.</span><span class="n">embedding_matrix</span><span class="p">)</span>

<span class="n">deepimage</span> <span class="o">=</span> <span class="n">DeepImage</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">freeze</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">head_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>...and, as we build the model, add a fully connected <em>head</em> via the input parameters (could also be used via the additional component/parameter <code>deephead</code>)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">WideDeep</span><span class="p">(</span><span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">,</span> <span class="n">deepdense</span><span class="o">=</span><span class="n">deepdense</span><span class="p">,</span> <span class="n">deeptext</span><span class="o">=</span><span class="n">deeptext</span><span class="p">,</span> <span class="n">deepimage</span><span class="o">=</span><span class="n">deepimage</span><span class="p">,</span> <span class="n">head_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's have a look to the model</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>WideDeep(
  (wide): Wide(
    (wide_linear): Embedding(357, 1, padding_idx=0)
  )
  (deepdense): DeepDense(
    (embed_layers): ModuleDict(
      (emb_layer_accommodates_catg): Embedding(4, 16)
      (emb_layer_bathrooms_catg): Embedding(4, 16)
      (emb_layer_bedrooms_catg): Embedding(5, 16)
      (emb_layer_beds_catg): Embedding(5, 16)
      (emb_layer_cancellation_policy): Embedding(6, 16)
      (emb_layer_guests_included_catg): Embedding(4, 16)
      (emb_layer_host_listings_count_catg): Embedding(5, 16)
      (emb_layer_minimum_nights_catg): Embedding(4, 16)
      (emb_layer_neighbourhood_cleansed): Embedding(33, 64)
    )
    (embed_dropout): Dropout(p=0.0, inplace=False)
    (dense): Sequential(
      (dense_layer_0): Sequential(
        (0): Linear(in_features=196, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01, inplace=True)
        (2): Dropout(p=0.5, inplace=False)
      )
      (dense_layer_1): Sequential(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01, inplace=True)
        (2): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (deeptext): DeepText(
    (word_embed): Embedding(2192, 100, padding_idx=1)
    (rnn): LSTM(100, 64, num_layers=2, batch_first=True, dropout=0.5)
  )
  (deepimage): DeepImage(
    (backbone): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (imagehead): Sequential(
      (dense_layer_0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01, inplace=True)
        (2): Dropout(p=0.0, inplace=False)
      )
      (dense_layer_1): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01, inplace=True)
        (2): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (deephead): Sequential(
    (head_layer_0): Sequential(
      (0): Linear(in_features=256, out_features=128, bias=True)
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
    )
    (head_layer_1): Sequential(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
    )
    (head_out): Linear(in_features=64, out_features=1, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a big model, so let me go component by component.</p>
<ol>
<li>
<p><code>wide</code>: simple linear model implemented via an <code>Embedding</code> layer</p>
</li>
<li>
<p><code>deepdense</code>: embeddings concatenated to categorical columns that are then passed through two dense layers with the following sizes [196 $\rightarrow$ 128 $\rightarrow$ 64].</p>
</li>
<li>
<p><code>deeptext</code>: two stacked LTSMs that will received the pre-trained glove wordvectors and output a last hidden state of dim 64 (this would be 128 if we had used <code>bidirectional = True</code>)</p>
</li>
<li>
<p><code>deepimage</code>: a pre-trained ResNet 18 model where only the last <code>Sequential</code> block (7) will be trained. The rest will remain "frozen". on top of it we have <code>imagehead</code> which is just a <code>Sequential</code> model comprised of two dense layers with the following sizes [512 $\rightarrow$ 256 $\rightarrow$ 128]</p>
</li>
<li>
<p><code>deephead</code>: on top of the 3 deep components we have a final component referred as <code>deephead</code> (this would correspond to the <code>architecture 2</code> described in the first post). This component will receive the concatenated output from all the deep components, and pass it through a further collection of dense layers. In this case the sizes are [256 $\rightarrow$ 64 $\rightarrow$ 1]. We input 256 because the output dim from <code>deepdense</code> is 64, the  output dim from <code>deeptext</code> is 64 and the output dim from <code>deeptext</code> is 128. The final <code>deephead</code> output dim is 1 because we are performing a regression, i.e. one output neuron with no activation function.</p>
</li>
</ol>
<p>Let's go even a step further and use different optimizers, initializers and schedulers for different components. Moreover, let's use a different learning rate for different parameter groups in the case of the <code>deepdense</code>, remember, this is <em>Kaggle mode</em>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Optimizers. Different parameter groups for the deepdense component will use different lr</span>
<span class="n">deep_params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">childname</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">childname</span> <span class="o">==</span> <span class="s1">'deepdense'</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span><span class="n">p</span> <span class="ow">in</span> <span class="n">child</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="s2">"emb_layer"</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span> <span class="n">deep_params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">p</span><span class="p">,</span> <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">deep_params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">p</span><span class="p">,</span> <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">})</span>
                
<span class="n">wide_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wide</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">deep_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">deep_params</span><span class="p">)</span>
<span class="n">text_opt</span> <span class="o">=</span> <span class="n">RAdam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deeptext</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">img_opt</span>  <span class="o">=</span> <span class="n">RAdam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deepimage</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">head_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deephead</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">wide_opt</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">deep_opt</span><span class="p">,</span> <span class="s1">'deeptext'</span><span class="p">:</span><span class="n">text_opt</span><span class="p">,</span> <span class="s1">'deepimage'</span><span class="p">:</span> <span class="n">img_opt</span><span class="p">,</span> <span class="s1">'deephead'</span><span class="p">:</span> <span class="n">head_opt</span><span class="p">}</span>

<span class="c1"># schedulers</span>
<span class="n">wide_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">wide_opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">deep_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span><span class="n">deep_opt</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="n">text_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">text_opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">img_sch</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span><span class="n">deep_opt</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="n">head_sch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">head_opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">schedulers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">wide_sch</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">deep_sch</span><span class="p">,</span> <span class="s1">'deeptext'</span><span class="p">:</span><span class="n">text_sch</span><span class="p">,</span> <span class="s1">'deepimage'</span><span class="p">:</span> <span class="n">img_sch</span><span class="p">,</span> <span class="s1">'deephead'</span><span class="p">:</span> <span class="n">head_sch</span><span class="p">}</span>

<span class="c1"># initializers</span>
<span class="n">initializers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'wide'</span><span class="p">:</span> <span class="n">KaimingNormal</span><span class="p">,</span> <span class="s1">'deepdense'</span><span class="p">:</span><span class="n">KaimingNormal</span><span class="p">,</span> 
                <span class="s1">'deeptext'</span><span class="p">:</span><span class="n">KaimingNormal</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">"^(?!.*word_embed).*$"</span><span class="p">),</span> <span class="c1"># do not initialize the pre-trained word-vectors!</span>
                <span class="s1">'deepimage'</span><span class="p">:</span><span class="n">KaimingNormal</span><span class="p">}</span>

<span class="c1"># transforms and callbacks</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.406</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.485</span><span class="p">]</span>  <span class="c1">#BGR</span>
<span class="n">std</span> <span class="o">=</span>  <span class="p">[</span><span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.229</span><span class="p">]</span>  <span class="c1">#BGR</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">ToTensor</span><span class="p">,</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)]</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">LRHistory</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">'model_weights/wd_out'</span><span class="p">)]</span>                
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that, since we will use pre-trained word embeddings, we do not want to initialize these embeddings. However you might still want to initialize the other layers in the <code>deeptext</code> component. This is not a problem, you can do that with the parameter <code>pattern</code> and your knowledge on regular  expressions. In the <code>deeptext</code> initializer definition above:</p>
<div class="highlight"><pre><span></span><span class="n">KaimingNormal</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">"^(?!.*word_embed).*$"</span><span class="p">)</span>
</pre></div>
<p>I am NOT initializing parameters whose name contains the string <code>word_embed</code>.</p>
<p>So...let's compile and run, which is as easy as:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">'regression'</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">,</span>
    <span class="n">lr_schedulers</span><span class="o">=</span><span class="n">schedulers</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide</span><span class="p">,</span> <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep</span><span class="p">,</span> <span class="n">X_text</span><span class="o">=</span><span class="n">X_text</span><span class="p">,</span> <span class="n">X_img</span><span class="o">=</span><span class="n">X_images</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">val_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [01:37&lt;00:00,  3.91s/it, loss=1.23e+4]
valid: 100%|██████████| 7/7 [00:15&lt;00:00,  2.26s/it, loss=1.24e+4]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As I mentioned early in the post, please, do not focus on the success metric/loss (<code>mse</code> in this case). I am just using a very small sample of the dataset and some "random" set up. I just want to illustrate usability. A benchmark post will come in the "no-so-distant future".</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Warm-up-routines">
<a class="anchor" href="#3.-Warm-up-routines" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Warm up routines<a class="anchor-link" href="#3.-Warm-up-routines"> </a>
</h2>
<p>When running <code>.fit</code>, we can choose to first "warm up" each model individually (similarly to fine-tunning if the model was pre-trained, but this is a general functionality, i.e. there is no need of a pre-trained model) before the joined training begins.</p>
<p><code>pytorch-widedeep</code> implements 3 different warming up routines:</p>
<ol>
<li>
<p>Warm up all trainable layers at once with a triangular one-cycle learning rate (referred as slanted triangular learning rates in <a href="https://arxiv.org/abs/1801.06146">Howard &amp; Ruder 2018</a> [1]). See <a href="https://github.com/jrzaurin/pytorch-widedeep/blob/master/examples/06_WarmUp_Model_Components.ipynb">here</a> for an example on this routine for a simpler <code>wide</code> + <code>deepdense</code> model.</p>
</li>
<li>
<p>Gradual warm up <em>inspired</em> by the work of <a href="https://arxiv.org/abs/1708.00524">Felbo et al., 2017</a> [2] for fine-tunning</p>
</li>
<li>
<p>Gradual warm up <em>inspired</em> by the work of <a href="https://arxiv.org/abs/1801.06146">Howard &amp; Ruder 2018</a> for fine-tunning</p>
</li>
</ol>
<p>Currently warming up is only supported without a fully connected <code>deephead</code>, i.e. if <code>deephead=None</code>. In addition, Felbo and Howard routines only applied to the <code>deeptext</code> and <code>deepimage</code> components. The <code>wide</code> and <code>deepdense</code> components can also be warmed up, but together, following the first of the 3 routines described before.</p>
<p>Let me briefly describe the "Felbo" and "Howard" routines before showing how to use them.</p>
<h3 id="3.1-The-Felbo-warm-up-routine">
<a class="anchor" href="#3.1-The-Felbo-warm-up-routine" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 The Felbo warm-up routine<a class="anchor-link" href="#3.1-The-Felbo-warm-up-routine"> </a>
</h3>
<p>The Felbo warm-up routine can be illustrated by the following figure:</p>
<p><figure>
  
    <img class="docimage" src="/infinitoml/images/copied_from_nb/figures/pytorch-widedeep/felbo_routine.png" alt="resnet_block" style="max-width: 500px">
    
    
</figure>
</p>
<p><strong>Figure 1</strong>. The process in the figure can be described as follows: warm up (or train) the last layer for one epoch using a one cycle triangular learning rate. Then warm up the next deeper layer for one epoch, with a learning rate that is a factor of 2.5 lower than the previous learning rate (the 2.5 factor is fixed) while freezing the already warmed up layer(s). Repeat untill all individual layers are warmed. Then warm one last epoch with all warmed layers trainable. The vanishing color gradient in the figure attempts to illustrate the decreasing learning rate.</p>
<p>Note that this is not identical to the Fine-Tunning routine described in Felbo et al, 2017, this is why I used the word '<em>inspired</em>' before.</p>
<h3 id="3.1-The-Howard-warm-up-routine">
<a class="anchor" href="#3.1-The-Howard-warm-up-routine" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 The Howard warm-up routine<a class="anchor-link" href="#3.1-The-Howard-warm-up-routine"> </a>
</h3>
<p>The Howard routine can be illustrated by the following figure:</p>
<p><figure>
  
    <img class="docimage" src="/infinitoml/images/copied_from_nb/figures/pytorch-widedeep/howard_routine.png" alt="resnet_block" style="max-width: 500px">
    
    
</figure>
</p>
<p><strong>Figure 2</strong>. The process in the figure can be described as follows: warm up (or train) the last layer for one epoch using a one cycle triangular learning rate. Then warm up the next deeper layer for one epoch, with a learning rate that is a factor of 2.5 lower than the previous learning rate (the 2.5 factor is fixed) while keeping the already warmed up layer(s) trainable. Repeat. The vanishing color gradient in the figure attempts to illustrate the decreasing learning rate.</p>
<p>Note that I write "<em>warm up (or train) the last layer for one epoch [...]</em>". However, in practice the user will have to specify the order of the layers to be warmed up. This is another reason why I wrote that the warm up routines I have implemented are inspired by the work of Felbo and Howard and not identical to their implemenations.</p>
<p>The felbo and howard routines can be accessed with via the <a href="https://pytorch-widedeep.readthedocs.io/en/latest/wide_deep.html#pytorch_widedeep.models.wide_deep.WideDeep.fit">warm up parameters</a>. Let's have a look:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wide</span> <span class="o">=</span> <span class="n">Wide</span><span class="p">(</span><span class="n">wide_dim</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_wide</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">deepdense</span> <span class="o">=</span> <span class="n">DeepDense</span><span class="p">(</span> <span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span>
                      <span class="n">deep_column_idx</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">deep_column_idx</span><span class="p">,</span>
                      <span class="n">embed_input</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">embeddings_input</span><span class="p">,</span>
                      <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">)</span>
<span class="n">deeptext</span> <span class="o">=</span> <span class="n">DeepText</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">text_preprocessor</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">),</span>
                    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">rnn_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                    <span class="n">embedding_matrix</span><span class="o">=</span><span class="n">text_preprocessor</span><span class="o">.</span><span class="n">embedding_matrix</span><span class="p">)</span>
<span class="n">deepimage</span> <span class="o">=</span> <span class="n">DeepImage</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">head_layers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WideDeep</span><span class="p">(</span><span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">,</span> <span class="n">deepdense</span><span class="o">=</span><span class="n">deepdense</span><span class="p">,</span> <span class="n">deeptext</span><span class="o">=</span><span class="n">deeptext</span><span class="p">,</span> <span class="n">deepimage</span><span class="o">=</span><span class="n">deepimage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">'regression'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a similar model to the one before but without the final <code>deephead</code>. There, we saw that the <code>deepimage</code> component, identical to the one discussed here, is comprised by a Sequential model that is a ResNet backbone and a Linear Layer.</p>
<p>In this example, I warm up the layers in the ResNet backbone, apart from the first sequence <code>[Conv2d -&gt; BatchNorm2d -&gt; ReLU -&gt; MaxPool2d]</code>, and the Linear layer.</p>
<p>This is done as follows:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">first_child</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deepimage</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">img_layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">first_child</span><span class="o">.</span><span class="n">backbone</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">4</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">deepimage</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">warm_img_layers</span> <span class="o">=</span> <span class="n">img_layers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide</span><span class="p">,</span> 
    <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep</span><span class="p">,</span> 
    <span class="n">X_text</span><span class="o">=</span><span class="n">X_text</span><span class="p">,</span> 
    <span class="n">X_img</span><span class="o">=</span><span class="n">X_images</span><span class="p">,</span> 
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> 
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
    <span class="n">val_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
    <span class="n">warm_up</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">warm_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">warm_deepimage_gradual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">warm_deepimage_layers</span><span class="o">=</span><span class="n">warm_img_layers</span><span class="p">,</span> 
    <span class="n">warm_deepimage_max_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
    <span class="n">warm_routine</span><span class="o">=</span><span class="s1">'howard'</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up wide for 1 epochs
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [00:00&lt;00:00, 28.55it/s, loss=1.59e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepdense for 1 epochs
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [00:00&lt;00:00, 44.05it/s, loss=1.25e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deeptext for 1 epochs
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [00:03&lt;00:00,  7.85it/s, loss=1.68e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepimage, layer 1 of 5
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [01:12&lt;00:00,  2.88s/it, loss=1.34e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepimage, layer 2 of 5
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [01:39&lt;00:00,  3.99s/it, loss=1.1e+4] 
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepimage, layer 3 of 5
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [01:59&lt;00:00,  4.78s/it, loss=1.08e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepimage, layer 4 of 5
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [02:25&lt;00:00,  5.81s/it, loss=1.05e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warming up deepimage, layer 5 of 5
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [03:08&lt;00:00,  7.53s/it, loss=1.08e+4]
  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [02:12&lt;00:00,  5.32s/it, loss=1.61e+4]
valid: 100%|██████████| 7/7 [00:16&lt;00:00,  2.43s/it, loss=1.4e+4] 
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Custom-model">
<a class="anchor" href="#4.-Custom-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Custom model<a class="anchor-link" href="#4.-Custom-model"> </a>
</h2>
<p>So far we have used the components that come with <code>pytorch-widedee</code>. However, as I mentioned in the first post, it is very likely that the user wants to use custom models for the <code>deeptext</code> and <code>deepimage</code> components. This is easily attainable by...well...simply passing your own model.</p>
<p>You should just remember that the model must return the last layer of activations (and NOT the predictions) and must contained an attribute called <code>output_dim</code> with the output dimension of  that last layer.</p>
<p>For example, let's say we want to use as <code>deeptext</code> a <strong>very</strong> simple stack of 2 bidirectional GRUs.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">MyDeepText</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyDeepText</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># word/token embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span>
        <span class="p">)</span>

        <span class="c1"># stack of RNNs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">embed_dim</span><span class="p">,</span>
            <span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Remember, this must be defined. If not WideDeep will through an error</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_embed</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
        <span class="n">o</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">h</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">h</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And from here, "<em>proceed as usual</em>"</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wide</span> <span class="o">=</span> <span class="n">Wide</span><span class="p">(</span><span class="n">wide_dim</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_wide</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">deepdense</span> <span class="o">=</span> <span class="n">DeepDense</span><span class="p">(</span> <span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span>
                      <span class="n">deep_column_idx</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">deep_column_idx</span><span class="p">,</span>
                      <span class="n">embed_input</span><span class="o">=</span><span class="n">deep_preprocessor</span><span class="o">.</span><span class="n">embeddings_input</span><span class="p">,</span>
                      <span class="n">continuous_cols</span><span class="o">=</span><span class="n">continuous_cols</span><span class="p">)</span>
<span class="n">mydeeptext</span> <span class="o">=</span> <span class="n">MyDeepText</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">text_preprocessor</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WideDeep</span><span class="p">(</span><span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">,</span> <span class="n">deepdense</span><span class="o">=</span><span class="n">deepdense</span><span class="p">,</span> <span class="n">deeptext</span><span class="o">=</span><span class="n">mydeeptext</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">'regression'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>WideDeep(
  (wide): Wide(
    (wide_linear): Embedding(357, 1, padding_idx=0)
  )
  (deepdense): Sequential(
    (0): DeepDense(
      (embed_layers): ModuleDict(
        (emb_layer_accommodates_catg): Embedding(4, 16)
        (emb_layer_bathrooms_catg): Embedding(4, 16)
        (emb_layer_bedrooms_catg): Embedding(5, 16)
        (emb_layer_beds_catg): Embedding(5, 16)
        (emb_layer_cancellation_policy): Embedding(6, 16)
        (emb_layer_guests_included_catg): Embedding(4, 16)
        (emb_layer_host_listings_count_catg): Embedding(5, 16)
        (emb_layer_minimum_nights_catg): Embedding(4, 16)
        (emb_layer_neighbourhood_cleansed): Embedding(33, 64)
      )
      (embed_dropout): Dropout(p=0.0, inplace=False)
      (dense): Sequential(
        (dense_layer_0): Sequential(
          (0): Linear(in_features=196, out_features=64, bias=True)
          (1): LeakyReLU(negative_slope=0.01, inplace=True)
          (2): Dropout(p=0.2, inplace=False)
        )
        (dense_layer_1): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): LeakyReLU(negative_slope=0.01, inplace=True)
          (2): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (deeptext): Sequential(
    (0): MyDeepText(
      (word_embed): Embedding(2192, 100, padding_idx=1)
      (rnn): GRU(100, 64, num_layers=2, batch_first=True, bidirectional=True)
    )
    (1): Linear(in_features=128, out_features=1, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_wide</span><span class="o">=</span><span class="n">X_wide</span><span class="p">,</span> <span class="n">X_deep</span><span class="o">=</span><span class="n">X_deep</span><span class="p">,</span> <span class="n">X_text</span><span class="o">=</span><span class="n">X_text</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">val_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 0/25 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>epoch 1: 100%|██████████| 25/25 [00:04&lt;00:00,  6.16it/s, loss=1.74e+4]
valid: 100%|██████████| 7/7 [00:00&lt;00:00, 21.47it/s, loss=9.35e+3]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="5.-Conclusion">
<a class="anchor" href="#5.-Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Conclusion<a class="anchor-link" href="#5.-Conclusion"> </a>
</h2>
<p>In this second post I tried to illustrate in detail the different functionalities of the <code>pytorch-widedeep</code> package, and how these can be used to customize each of the four potential components of the <code>WideDeep</code> model that can be built with <code>pytorch-widedeep</code>. I have also describe the warm-up routines that can be used to "warm-up" each individual component before the joined training and finally, how custom models, "external" to <code>pytorch-widedeep</code> can be used in combination with the package.</p>
<p>However, this is not the end of the journey. As you will have seen, there is an "<em>imbalance in the <code>pytorch-widedeep</code> force</em>", in the sense that while fully pre-trained models are incorporated for the <code>deepimage</code> component, this is not the case for the <code>deeptext</code> component, where only pre-trained word embeddings are considered. Of course, as illusttrated in Section 4, you could build your own pre-trained <code>deeptext</code> component and pass it to the <code>WideDeep</code> constructor class, but eventually, I want to allow that option within the package.</p>
<p>This means that eventually I will need to integrate the library with some of the pre-trained Language models available or simply code a custom version for <code>pytorch-widedeep</code>.</p>
<p>One the other hand, if there is one Deep Learning for Tabular data implementation that is becoming more and more popular is <a href="">TabNet</a>. There is already a fantastic <a href="https://github.com/dreamquark-ai/tabnet"><code>Pytorch</code> implementation</a> which I highly recommend. I believe I could adapt that implementation to <code>pytorch-widedeep</code> and offer it as a deep component or on its own, like any other model component.</p>
<p>I am pretty sure I will think of a few more things along the way.</p>
<p>If you made it this far, thanks for reading! And if you use the package, let me know your thoughts!</p>
<h4 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h4>
<p>[1] Universal Language Model Fine-tuning for Text Classification. Jeremy Howard, Sebastian Ruder, 2018 <a href="https://arxiv.org/abs/1801.06146">arXiv:1801.06146v5</a></p>
<p>[2] Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm. Bjarke Felbo, Alan Mislove, Anders Søgaard, et al., 2017. <a href="https://arxiv.org/abs/1708.00524">arXiv:1708.00524</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="jrzaurin/infinitoml"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/infinitoml/2020/12/11/pytorch-widedeep_ii.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/infinitoml/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/infinitoml/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/infinitoml/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>limitless or endless in space, extent, or size; impossible to measure or calculate.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jrzaurin" title="jrzaurin"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/javier-rodriguez-zaurin-06277454" title="javier-rodriguez-zaurin-06277454"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/jrzaurin" title="jrzaurin"><svg class="svg-icon grey"><use xlink:href="/infinitoml/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
