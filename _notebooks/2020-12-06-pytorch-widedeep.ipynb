{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"pytorch-widedeep: deep learning for tabular data\"\n",
    "> a flexible package to combine tabular data with text and images using wide and deep models.\n",
    "\n",
    "- author: Javier Rodriguez\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post I describe the main components of the `Python` library `pytorch-widedeep`, which is intended to be a flexible package to use Deep Learning (hereafter DL) with tabular data and combine it with text and images via wide and deep models. `pytorch-widedeep` is based on Heng-Tze Cheng et al., 2016 [paper](https://arxiv.org/abs/1606.07792). \n",
    "\n",
    "## 1. Installation \n",
    "\n",
    "To install the package simply use pip:\n",
    "\n",
    "```bash\n",
    "pip install pytorch-widedeep\n",
    "```\n",
    "\n",
    "or directly from github\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/jrzaurin/pytorch-widedeep.git\n",
    "```\n",
    "\n",
    "**Important note for Mac Users**\n",
    "\n",
    "Note that the following comments are not directly related to the package, but to the interplay between `pytorch` and OSX (more precisely `pytorch`'s dependency on `OpenMP` I believe) and in general parallel processing in Mac. \n",
    "\n",
    "In the first place, at the time of writing the latest `pytorch` version is `1.7`. This version is known to have some [issues](https://stackoverflow.com/questions/64772335/pytorch-w-parallelnative-cpp206) when running on Mac and the data-loaders might not run in parallel. On the other hand, since `Python 3.8` the `multiprocessing` library start method changed from ['fork' to 'spawn'](https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods). This also affects the data-loaders (for any torch version) and they will not run in parallel. \n",
    "\n",
    "Therefore, for Mac users I suggest using `python 3.7` and `torch <= 1.6` (with its corresponding `torchvision` version, i.e. `<= 0.7.0`). I could have enforced this versioning via the `setup.py` file. However, there are a number of unknowns and I preferred to leave it as it is. For example I developed the package using macOS Catalina and maybe some of this issues are not present in the new release Big Sur. Also, I hope that they release soon a patch for `pytorch 1.7` and some, if not all these problems disappear. \n",
    "\n",
    "Installing `pytorch-widedeep` via `pip` will install the latest version. Therefore, if these problems are present and the dataloaders do not run in parallel, one can easily downgrade manually: \n",
    "\n",
    "```bash\n",
    "pip install torch==1.6.0 torchvision==0.7.0\n",
    "```\n",
    "\n",
    "*None of these issues affect Linux users*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.`pytorch-widedeep`  DL Architectures\n",
    "\n",
    "As I mentioned earlier `pytorch-widedeep` combines tabular data with text and images via wide and deep models. With that in mind, the two main architectures one can build with a few lines of code using `pytorch-widedeep` are:\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"700\" src=\"figures/pytorch-widedeep/arch_1.png\">\n",
    "</p>\n",
    "\n",
    "**Architecture 1**: architecture 1 combines the `Wide`, linear model with the outputs from the `DeepDense` or `DeepDenseResnet`, `DeepText` and `DeepImage` components connected to a final output neuron or neurons, depending on whether we are performing a binary classification or regression, or a multi-class classification. The components within the faded-pink rectangles are concatenated. Later in the post I will describe in detail each of the components, for now, let's just move on.\n",
    "\n",
    "In math terms, and following the notation in the [paper](https://arxiv.org/abs/1606.07792), Architecture 1 can be formulated as:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"500\" src=\"figures/pytorch-widedeep/architecture_1_math.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Where $W$ are the weight matrices applied to the wide model and to the final activations of the deep models, '$a$' are these final activations, and $\\phi(x)$ are the cross product transformations of the original features '$x$'. In case you are wondering what are *\"cross product transformations\"*, here is a quote taken directly from the paper: *\"For binary features, a cross-product transformation (e.g., “AND(gender=female, language=en)”) is 1 if and only if the constituent features (“gender=female” and “language=en”) are all 1, and 0 otherwise\"*.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"700\" src=\"figures/pytorch-widedeep/arch_2.png\">\n",
    "</p>\n",
    "\n",
    "**Architecture 2**: architecture 2 combines the `Wide`, linear model with the `Deep` components of the model connected to the output neuron(s), after the different Deep components have been themselves combined through a FC-Head (that I refer as `DeepHead`).\n",
    "\n",
    "In math terms, and following the notation in the [paper](https://arxiv.org/abs/1606.07792), Architecture 2 can be formulated as:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"300\" src=\"figures/pytorch-widedeep/architecture_2_math.png\">\n",
    "</p>\n",
    "\n",
    "Is imporrtant to metion that each individual component, `wide`, `deepdense` (either `DeepDense` or `DeepDenseResnet`), `deeptext` and `deepimage`, can be used independently and in isolation. For example, one could use only `wide`, which is in simply a linear model. Or use `DeepDense` which is in essence a similar implementation to that of the [Tabular](https://docs.fast.ai/tabular.learner) API in the fastai library (which I strongly recommend)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick start\n",
    "\n",
    "Before diving into the details of the library let's just say that you just want to quickly run one example and get the feel of how `pytorch-widedeep` works. Let go through a quick example using the adult census dataset. In this example we will be fitting a model comprised by a `Wide` and `DeepDense` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "adult = pd.read_csv(\"data/adult/adult.csv.zip\")\n",
    "adult.columns = [c.replace(\"-\", \"_\") for c in adult.columns]\n",
    "adult[\"income_label\"] = (adult[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "adult.drop(\"income\", axis=1, inplace=True)\n",
    "\n",
    "for c in adult.columns:\n",
    "    if adult[c].dtype == 'O':\n",
    "        adult[c] = adult[c].apply(lambda x: \"unknown\" if x == \"?\" else x)\n",
    "        adult[c] = adult[c].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>never-married</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>own-child</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>private</td>\n",
       "      <td>89814</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>farming-fishing</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>protective-serv</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>private</td>\n",
       "      <td>160323</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>husband</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>unknown</td>\n",
       "      <td>103497</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>never-married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>own-child</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital_status  \\\n",
       "0   25    private  226802          11th                7       never-married   \n",
       "1   38    private   89814       hs-grad                9  married-civ-spouse   \n",
       "2   28  local-gov  336951    assoc-acdm               12  married-civ-spouse   \n",
       "3   44    private  160323  some-college               10  married-civ-spouse   \n",
       "4   18    unknown  103497  some-college               10       never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital_gain  capital_loss  \\\n",
       "0  machine-op-inspct    own-child  black    male             0             0   \n",
       "1    farming-fishing      husband  white    male             0             0   \n",
       "2    protective-serv      husband  white    male             0             0   \n",
       "3  machine-op-inspct      husband  black    male          7688             0   \n",
       "4            unknown    own-child  white  female             0             0   \n",
       "\n",
       "   hours_per_week native_country  income_label  \n",
       "0              40  united-states             0  \n",
       "1              50  united-states             0  \n",
       "2              40  united-states             1  \n",
       "3              40  united-states             1  \n",
       "4              30  united-states             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:02<00:00, 52.44it/s, loss=0.526, metrics={'acc': 0.7471}]\n",
      "epoch 2: 100%|██████████| 153/153 [00:02<00:00, 57.72it/s, loss=0.409, metrics={'acc': 0.8116}]\n",
      "predict: 100%|██████████| 39/39 [00:00<00:00, 196.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_widedeep.preprocessing import WidePreprocessor, DensePreprocessor\n",
    "from pytorch_widedeep.models import Wide, DeepDense, WideDeep\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "\n",
    "adult_train, adult_test = train_test_split(adult, test_size=0.2, stratify=adult.income_label)\n",
    "\n",
    "# prepare wide, crossed, embedding and continuous columns and target\n",
    "wide_cols = [\"education\", \"relationship\", \"workclass\", \"occupation\", \"native_country\", \"gender\"]\n",
    "cross_cols = [(\"education\", \"occupation\"), (\"native_country\", \"occupation\")]\n",
    "embed_cols = [(\"education\", 10), (\"workclass\", 10), (\"occupation\", 10), (\"native_country\", 10)]\n",
    "cont_cols = [\"age\", \"hours_per_week\"]\n",
    "target = adult_train[\"income_label\"].values\n",
    "\n",
    "# wide component\n",
    "preprocess_wide = WidePreprocessor(wide_cols=wide_cols, crossed_cols=cross_cols)\n",
    "X_wide = preprocess_wide.fit_transform(adult_train)\n",
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "\n",
    "# deepdense component\n",
    "preprocess_deep = DensePreprocessor(embed_cols=embed_cols, continuous_cols=cont_cols)\n",
    "X_deep = preprocess_deep.fit_transform(adult_train)\n",
    "deepdense = DeepDense(hidden_layers=[64, 32], deep_column_idx=preprocess_deep.deep_column_idx, \n",
    "                      embed_input=preprocess_deep.embeddings_input, continuous_cols=cont_cols)\n",
    "\n",
    "# build, compile and fit\n",
    "model = WideDeep(wide=wide, deepdense=deepdense)\n",
    "model.compile(method=\"binary\", metrics=[Accuracy])\n",
    "model.fit(X_wide=X_wide, X_deep=X_deep, target=target, n_epochs=2, batch_size=256) \n",
    "\n",
    "# predict\n",
    "X_wide_te = preprocess_wide.transform(adult_test)\n",
    "X_deep_te = preprocess_deep.transform(adult_test)\n",
    "preds = model.predict(X_wide=X_wide_te, X_deep=X_deep_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
