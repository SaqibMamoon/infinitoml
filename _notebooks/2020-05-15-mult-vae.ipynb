{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"RecoTour III: Variational Autoencoders for Collaborative Filtering with Mxnet and Pytorch\"\n",
    "> An deep dive into the use of Variational Autoencoders for Collaborative Filtering\n",
    "\n",
    "- author: Javier Rodriguez\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post and the code here are part of a larger repo called [RecoTour](https://github.com/jrzaurin/RecoTour), where I normally explore and implement some recommendation algorithms that I consider interesting and/or useful (see [RecoTour](https://medium.com/datadriveninvestor/recotour-a-tour-through-recommendation-algorithms-in-python-52d780628ab9) and [RecoTourII](https://towardsdatascience.com/recotour-ii-neural-recommendation-algorithms-49733938d56e)). In every directory, I have included a `README` file and a series of explanatory notebooks that I hope help explaining the code. I keep adding algorithms from time to time, so stay tunned if you are interested. \n",
    "\n",
    "As always, let me first acknowledge the relevant people that did the hard work. This post and the companion repo are based on the paper “Variational Autoencoders for Collaborative Filtering” [1]. The code in that repo is partially inspired in the implementation by [Younggyo Seo](https://github.com/younggyoseo/vae-cf-pytorch). I have adapted the code to my coding preferences and added some options and flexibility to run multiple experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Partially Regularized Multinomial Variational  Autoencoder\n",
    "\n",
    "...or $\\text{Mult-VAE}^{\\text{PR}}$...I must admit that when it comes to variational autoencoders (VAEs) I find that there is a \"notable\" difference between the complexity of the math and that of the code (or maybe is just me that I am not a mathematician). Nonetheless, I think that speaking about VAEs and not mentioning log likelihoods, Evidence Lower Bound (EBLO) or the Kullback–Leibler divergence ($\\text{D}_{\\text{KL}}$) is almost like \"cheating\". With that in mind I will try to give some mathematical context to the $\\text{Mult-VAE}^{\\text{PR}}$ for collaborative filtering and then move to the code, from how one prepares the data to a discussion of the results. Bear in mind that the whole purpose of the math below is to justify the loss function we will be using when training the $\\text{Mult-VAE}^{\\text{PR}}$ as well as the architecture of the algorithm.\n",
    "\n",
    "Before diving into the problem scenario and the mathematical formulation, let me describe the notational convention. Following [Liang et al., 2018](https://arxiv.org/pdf/1802.05814.pdf), I will use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. The user-by-item **binary** interaction matrix (i.e. the click matrix) is $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$ and I will use lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ to refer to the click history of an individual user $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem scenario\n",
    "\n",
    "We are given a dataset $\\mathbf{X} = \\{ {\\mathbf{x}_u} \\}^{U}_{u=1}$ of user clicks (a more general scenario is described in \"[Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf)\" [2]). Our job is to estimate the parameters of the underlying probability distribution so that we can do inference. In other words, we need to find a statistical model of the data. To do this, we need to maximize the likelihood function so that under the assumed statistical model the observed data is most probable. \n",
    "\n",
    "To find the maximum likelihood we normally assume that the statistical model of the data involves some latent variable $\\bf{z}$, so that the marginal likelihood can be written as:\n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\mathbf{x}_u) = \\int {p_{\\theta}(\\mathbf{z}_u)p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}_u) d\\mathbf{z}_u} \\hspace{1cm} (1) \n",
    "$$\n",
    "\n",
    "Eq (1) is solvable if we assume that both the prior $p_{\\theta}(\\mathbf{z}_u)$ and the conditional probability $p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}_u)$ come from parametric families of distributions and that their PDFs are differentiable almost everywhere w.r.t. both $\\theta$ and $\\mathbf{z}_u$. However, for \"*moderately*\" complicated likelihood functions $p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}_u)$, such as a neural network with a nonlinear layer, Eq (1) is not intractable (it is not possible to evaluate of differentiate the marginal likelihood). Furthermore, the true posterior  $p_{\\theta}(\\mathbf{z}_u \\vert \\mathbf{x}_u) = p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}_u)p_{\\theta}(\\mathbf{z}_u)/p_{\\theta}(\\mathbf{x}_u)$ is also intractable, and therefore we cannot use an EM algorithm (since the E-step involves the computation of the true posterior at a given iteration). \n",
    "\n",
    "To address these, and some other limitations, [Kingma and Welling 2014](https://arxiv.org/pdf/1312.6114.pdf) proposed a flexible neural network based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Auto-Encoding Variational Bayes\n",
    "\n",
    "The following Section is both a summary and my understanding of the paper \"[Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf)\" to which I keep referring and that I strongly recommend reading. \n",
    "\n",
    "Let me remind you: our goal is to maximize the likelihood, or more conveniently the log likelihood $\\log p_{\\theta}(\\mathbf{X})$, where:\n",
    "\n",
    "$$\n",
    "\\log p_{\\theta}(\\mathbf{X}) = \\sum_u \\log p_{\\theta}(\\mathbf{x}_u) \\hspace{1cm} (2) \n",
    "$$\n",
    "\n",
    "Each term in the summation can be re-written as:\n",
    "\n",
    "$$\n",
    "\\log p_{\\theta}(\\mathbf{x}_u) = D_{KL}\\left(q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\| p_\\theta(\\textbf{z}_u \\vert \\textbf{x}_u)\\right) + \\underbrace{\\mathbb{E} \\small{ q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u) } \\left[ -\\log q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x_u}) + \\log p_{\\theta}(\\mathbf{x}_u, \\mathbf{z}_u) \\right]}_{ELBO \\mathcal L(\\textbf{x}_u, \\phi,\\theta)} \\hspace{1cm} (3)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Where the first elements in the right hand side is the [Kullback–Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) ($\\text{D}_{\\text{KL}}$) and $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$ is the approximate posterior of the true posterior $p_\\theta(\\textbf{z}_u \\vert \\textbf{x}_u)$. Eq (3) is our \"*point of entry*\" from which we will derive the remaining equations. If you want proof of Eq (3) I would recommend reading [this tutorial](https://vannevar.ece.uw.edu/techsite/papers/documents/UWEETR-2010-0002.pdf) or this [\"crazy\" post](https://medium.com/@jonathan_hui/machine-learning-summary-proof-terms-8ca7c588905e). \n",
    "\n",
    "Moving on, given that $\\text{D}_{\\text{KL}}$ is non-negative, $\\log p_{\\theta}(\\mathbf{x}_u) \\geq  \\mathcal L(\\textbf{x}_u, \\phi,\\theta)$ and therefore  $\\mathcal L$ is referred as Evidence Lower Bound (ELBO). It is straightforward to understand from Eq (3) that maximizing $\\log p_{\\theta}(\\mathbf{x}_u)$ implies maximizing ELBO $\\mathcal L$. If we re-order the terms in that equation, we could also think of the problem as follows: maximizing ELBO $\\mathcal L$ implies minimizing $\\text{D}_{\\text{KL}}$, which makes sense, since $D_{KL}$ measures the dissimilarity between the approximate posterior  $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$ and the true posterior $p_{\\theta}(\\textbf{z}_u\\vert \\textbf{x}_u)$. \n",
    "\n",
    "ELBO $\\mathcal L$ in Eq (3) can also be re-written as:\n",
    "\n",
    "$$\n",
    "\\mathcal L(\\textbf{x}_u, \\phi,\\theta) =  - D_{KL}\\left(q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\| p_\\theta(\\textbf{z}_u \\right) + \\mathbb{E} \\small{ q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u) } \\left[ \\log p_{\\theta}(\\textbf{x}_u\\vert \\textbf{z}_u) \\right] \\hspace{1cm} (4)\n",
    "$$\n",
    "\n",
    "We can see that Eq (4) involves sampling $\\tilde{\\mathbf{z}_u} \\sim q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u)$. When sampling is involved, backpropagation is not trivial (how one would take gradients with respect to $\\phi$?). To remedy this situation the authors used the so called \"*reparameterization trick*\". Instead of sampling from the approximate postertior $q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u)$, the authors used a differentiable transformation $g_{\\phi}(\\mathbf{\\epsilon}, \\mathbf{x}_u)$ of a noise variable $\\epsilon$, such that:\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{z}_u} = g_{\\phi}(\\mathbf{\\epsilon}, \\mathbf{x}_u) \\hspace{1cm} with \\hspace{1cm} \\mathbf{\\epsilon} \\sim p(\\epsilon) \\hspace{1cm} (5)\n",
    "$$\n",
    "\n",
    "where $p(\\epsilon)$ can be, for example, a variable sampled from a random normal distribution (see Section 1.3 for the selection of $g_{\\phi}$ in the particular case of the $\\text{Mult-VAE}^{\\text{PR}}$). With these formulation, one can use Monte Carlo estimates of expectations of some function $f(\\mathbf{z})$ with respect to $q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u)$ such that: \n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\small{ q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u) }\\left[ f(\\mathbf{z}_u) \\right] =  \\mathbb{E} \\small{ q_{\\phi}(\\mathbf{z}_u \\vert \\mathbf{x}_u) }\\left[ f(g_{\\phi}(\\mathbf{\\epsilon}, \\mathbf{x}_u)) \\right] \\simeq \\frac{1}{L} \\sum_{l=1}^{L} f(g_{\\phi}(\\mathbf{\\epsilon}^l), \\mathbf{x}_u) \n",
    "\\\\\n",
    "\\text{where} \\hspace{1cm} \\mathbf{\\epsilon}^l \\sim p(\\epsilon) \\hspace{1cm} (6)\n",
    "$$\n",
    "\n",
    "Replacing the second term in Eq (4) with the result in Eq (6), we see that the ELBO $\\mathcal L$ can be approximated by what Kingma and Welling called generic Stochastic Gradient Variational Bayes (SGVB) estimator $\\tilde{\\mathcal L}(\\textbf{x}_u, \\phi,\\theta) \\simeq \\mathcal L(\\textbf{x}_u, \\phi,\\theta)$:\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathcal L}(\\mathbf{x}_u, \\phi,\\theta) = - D_{KL}\\left(q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\| p_\\theta(\\textbf{z}_u \\right) + \\frac{1}{L} \\sum_{l=1}^{L} \\log p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}^l_u) \\\\\n",
    "\\text{where} \\hspace{1cm} \\mathbf{z}^l_u = g_{\\phi}(\\epsilon^l_u,  \\mathbf{x}_u) \\hspace{1cm} \\text{and} \\hspace{1cm} \\epsilon^l \\sim p(\\epsilon) \\hspace{1cm} (7)\n",
    "$$\n",
    "\n",
    "Before we move on to Multinomial variational autoencoders, there is one more important result to discuss. When running a practical application, we will be using minibatches, so that: \n",
    "\n",
    "$$\n",
    "\\mathcal L(\\mathbf{\\text{X}}^M, \\phi,\\theta) \\simeq \\tilde{\\mathcal L}^{M}(\\mathbf{\\text{X}}^M, \\phi,\\theta) = \\frac{1}{M} \\sum_{u=1}^{M} \\tilde{\\mathcal L}(\\mathbf{x}_u, \\phi,\\theta) \\hspace{1cm} (8)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}^M = \\{\\mathbf{x}_u \\}_{u=1}^M$ is a minibatch of M users. In their experiments the authors found that the number of samples $L$ can be set to 1 as long as the minibatch size was large enough, e.g. $M$ = 100. With this in mind, as long as our batch sizes are of 100 or more, Eq (7) can be re-written as:\n",
    "\n",
    "$$\n",
    "\\mathcal L(\\mathbf{\\text{X}}^M, \\phi,\\theta) \\simeq \\frac{1}{M} \\sum_{u=1}^{M} - D_{KL}\\left(q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\| p_\\theta(\\textbf{z}_u \\right) + \\log  p_{\\theta}(\\mathbf{x}_u \\vert \\mathbf{z}^s_u) \\hspace{1cm} (9)\n",
    "$$\n",
    "\n",
    "Note that $\\mathbf{z}^s_u$ signifies that $\\mathbf{z}_u$ stil needs to be sampled once from $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$, but using the reparameterization trick this will be rather easy, as we will see in the next section. Finally, now that we have a \"nice looking\" mathematical expression, this is how Auto-Encoding Variational Bayes works: \n",
    "\n",
    "1. Select a prior for latent representation of $\\textbf{x}_u$, $p_{\\theta}(\\textbf{z}_u)$\n",
    "2. Use a neural network to parameterize the distribution $p_{\\theta}(\\textbf{x}_u\\vert \\textbf{z}_u)$. Because this part of the model maps the latent variable/representation $\\textbf{z}_u$ to the observed data $\\textbf{x}_u$, it is referred as a \"*decoder*\" network. \n",
    "3. Rather than explicitly calculating the intractable posterior $p_{\\theta}(\\textbf{z}_u\\vert \\textbf{x}_u)$, use another another neural network to parameterize the distribution $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$ as the approximate posterior. Since $q_\\phi$ maps the observed data $\\textbf{x}_u$ to the latent space of $\\textbf{z}_u$'s, is referred as the \"*encoder*\" network.\n",
    "4. maxmize ELBO $\\mathcal{L}$ in Eq (9) using Stochastic Gradient Descent or any of its cousins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The $\\text{Mult-VAE}^{\\text{PR}}$\n",
    "\n",
    "The set up used by [Liang and co-authors](https://arxiv.org/pdf/1802.05814.pdf) is the following: for each user $u$, the latent representation $\\textbf{z}_u$ is assumed to be drawn from a standard Gaussian prior $p(\\textbf{z}_u) \\sim \\mathcal N(0, I)$. Such representation is then transformed by a multi-layer perceptron (MLP), and the output is normalized via a Softmax function to produce a probability distribution over all items **$I$**, $\\pi(\\mathbf{z}_u) = Softmax(MLP(\\mathbf{z}_u))$. Then, the click history of user $u$ is assumed to be drawn from a Multinomial distribution with probability $\\pi(\\mathbf{z}_u)$: \n",
    "\n",
    "$$\n",
    "\\textbf{x}_u \\sim \\text{Mult}(N_u, \\pi(\\mathbf{z}_u)) \\hspace{1cm} (10)\n",
    "$$\n",
    "\n",
    "where $N_u = \\sum_i x_{ui}$ is the total number of clicks for user $u$. In this set up, the log-likelihood of the click history $\\mathbf{x}_u$ conditioned to the latent representation $\\mathbf{z}_u$ is simply:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\log(p_{\\theta}(\\textbf{x}_u\\vert \\textbf{z}_u)) = \\mathbf{x}_u \\log(\\pi(\\mathbf{z}_u)) \\hspace{1cm} (11)\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The posterior $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$ is also chosen to be a standard Gaussian $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\sim \\mathcal N(\\mu_\\phi(\\textbf{x}_u), \\sigma_\\phi(\\textbf{x}_u) I)$ where $\\mu_\\phi(\\textbf{x}_u)$ and  $\\sigma_\\phi(\\textbf{x}_u)$ are functions implemented as neural networks. Then, we use the reparameterization trick and chose $g_{\\phi}(\\mathbf{\\epsilon}, \\mathbf{x}_u) = \\mu(\\textbf{x}_u) + \\sigma(\\textbf{x}_u) \\cdot \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0,I)$. This way $\\mathbf{z}^s_u = \\mu(\\textbf{x}_u) + \\sigma(\\textbf{x}_u) \\cdot \\epsilon$ where we sample directly $\\epsilon$. \n",
    "\n",
    "At this stage we have defined the Gaussian prior, the Gaussian approximate posterior and our sampled latent representation. We are finally ready to write the loss function that we will minimize when training the Mult-VAE:\n",
    "\n",
    "$$\n",
    "Loss = -\\frac{1}{M} \\sum_{u=1}^{M} \\left[ \\mathbf{x}_u \\log(\\pi(\\mathbf{z}_u)) + \\frac{\\beta}{2}  \\sum_j ( 1 + \\log(\\sigma_{uj}^2) - \\mu_{uj}^2 - \\sigma_{uj}^2 )  \\right] \\hspace{1cm} (12)\n",
    "$$\n",
    "\n",
    "Note that the expression above is the negative ELBO $\\mathcal L$ (maximizing $\\mathcal L$ is equivalent to minimize -$\\mathcal L$) with a multiplicative factor $\\beta$ applied to the $D_{KL}$. For the behind the $D_{KL}$ expression given this set up have a look here [here](https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes). \n",
    "\n",
    "Let me just comment on that $\\beta$. Looking at the loss function in Eq (12) within the context of VAEs, we can see that the first term is the reconstruction loss, while the $D_{KL}$ act as a regularizer. With that in mind, Liang et al add a factor $\\beta$ to control the strength of the regularization, and propose $\\beta < 1$. Let's paused for one second and think on what this means. First of all, we are no longer optimizing a lower bound for a given log likelihood. In addition, remember that the $D_{KL}$ divergence measures the similarity between the approximate posterior $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u)$ and the prior $p_\\theta(\\textbf{z}_u)$. Therefore, by using $\\beta < 1$ we are weakening the influence of the prior constrain $q_\\phi(\\textbf{z}_u\\vert \\textbf{x}_u) \\approx p_\\theta(\\textbf{z}_u)$ on the loss. This means that we are less able to generalize to novel user clicks from historical data. However, when building recommendation systems we are often not interested in reproducing precisely click histories (i.e. achieving the best loss) but in making good recommendations (i.e. achieving the best ranking metrics). As the authors show in the [paper](https://arxiv.org/pdf/1802.05814.pdf) (and we will see here later), the best ranking metrics are obtained when using $\\beta < 1$ and in consequence they name the algorithm Partially Regularized Multinomial Autoencoder or $\\text{Mult-VAE}^{\\text{PR}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the data\n",
    "\n",
    "Throughout this exercise I will use two dataset. The [Amazon Movies and TV](http://jmcauley.ucsd.edu/data/amazon/) dataset [3] [4] and the [Movilens](https://grouplens.org/datasets/movielens/20m/) dataset. The later is mainly use so I can make sure I am obtaining consistent results to those obtained in the paper. As we will see through the notebook, the Amazon dataset is significantly more challenging that the Movielens dataset.\n",
    "\n",
    "The data preparation is fairly simple, and is identical for both datasets. Therefore, I will focus here only on the Amazon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from typing import Tuple, Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath('/Users/javier/ml_experiments_python/RecoTour/Amazon/mult-vae/'))\n",
    "datapath = \"/Users/javier/ml_experiments_python/RecoTour/Amazon/mult-vae/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(datapath)\n",
    "new_colnames = [\"user\", \"item\", \"rating\", \"timestamp\"]\n",
    "\n",
    "inp_path = DATA_DIR / \"amazon-movies\"\n",
    "filename = \"reviews_Movies_and_TV_5.p\"\n",
    "raw_data = pd.read_pickle(inp_path / filename)\n",
    "keep_cols = [\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]\n",
    "raw_data = raw_data[keep_cols]\n",
    "raw_data.columns = new_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1697533, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1203984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>5</td>\n",
       "      <td>1202860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1387670400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0   ADZPIG9QOCDG5  0005019281       4  1203984000\n",
       "1  A35947ZP82G7JH  0005019281       3  1388361600\n",
       "2  A3UORV8A9D5L2E  0005019281       3  1388361600\n",
       "3  A1VKW06X1O2X7V  0005019281       5  1202860800\n",
       "4  A3R27T4HADWFFJ  0005019281       4  1387670400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filter triples (user, item, score)\n",
    "\n",
    "The first thing that the we do is to \"filter triples\" (hereafter refereed as `tp`) based on the number of times a user interacted with items (min_user_click) or items that where \"interacted with\" by a user a given number of times (min_item_click). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def get_count(tp: pd.DataFrame, id: str) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Returns `tp` groupby+count by `id`\n",
    "    \"\"\"\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "\n",
    "def filter_triplets(\n",
    "    tp: pd.DataFrame, min_user_click, min_item_click\n",
    ") -> Tuple[pd.DataFrame, pd.Index, pd.Index]:\n",
    "    \"\"\"\n",
    "    Returns triplets (`tp`) of user-item-rating for users/items with \n",
    "    more than min_user_click/min_item_click counts\n",
    "    \"\"\"\n",
    "    if min_item_click > 0:\n",
    "        itemcount = get_count(tp, \"item\")\n",
    "        tp = tp[tp[\"item\"].isin(itemcount.index[itemcount >= min_item_click])]\n",
    "\n",
    "    if min_user_click > 0:\n",
    "        usercount = get_count(tp, \"user\")\n",
    "        tp = tp[tp[\"user\"].isin(usercount.index[usercount >= min_user_click])]\n",
    "\n",
    "    usercount, itemcount = get_count(tp, \"user\"), get_count(tp, \"item\")\n",
    "\n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw_data, user_activity, item_popularity = filter_triplets(\n",
    "    raw_data, min_user_click=5, min_item_click=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since I am using the \"reviews_Movies_and_TV_5\" (i.e. the 5-core dataset, where users and items have at least 5 reviews each) filtered_raw_data has no effect on the Amazon dataset. It does however filter some users/items in the case of the Movilens dataset.\n",
    "\n",
    "Let's now have a look to the sparsity of the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 1697533 watching events from 123960 users and 50052 movies (sparsity: 0.027%)\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sparsity = (\n",
    "    1.0\n",
    "    * filtered_raw_data.shape[0]\n",
    "    / (user_activity.shape[0] * item_popularity.shape[0])\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\"\n",
    "    % (\n",
    "        filtered_raw_data.shape[0],\n",
    "        user_activity.shape[0],\n",
    "        item_popularity.shape[0],\n",
    "        sparsity * 100,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these numbers to those of the Movilens dataset (9990682 watching events from 136677 users and 20720 movies: sparsity: 0.353%. see the [notebook](https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb) corresponding to the original publication, or the [original publication](https://arxiv.org/pdf/1802.05814.pdf) itself) one can see that the Amazon dataset is $\\sim$13 times more sparse than the Movielens dataset. In consequence, I one would expect that the algorithm finds it more challenging, resulting in lower ranking metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train, validation and test split\n",
    "\n",
    "Once the raw data is filtered, we follow the same procedure than that of the original authors to split the users into training, validation and test users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def split_users(\n",
    "    unique_uid: pd.Index, test_users_size: Union[float, int]\n",
    ") -> Tuple[pd.Index, pd.Index, pd.Index]:\n",
    "\n",
    "    n_users = unique_uid.size\n",
    "\n",
    "    if isinstance(test_users_size, int):\n",
    "        n_heldout_users = test_users_size\n",
    "    else:\n",
    "        n_heldout_users = int(test_users_size * n_users)\n",
    "\n",
    "    tr_users = unique_uid[: (n_users - n_heldout_users * 2)]\n",
    "    vd_users = unique_uid[(n_users - n_heldout_users * 2) : (n_users - n_heldout_users)]\n",
    "    te_users = unique_uid[(n_users - n_heldout_users) :]\n",
    "\n",
    "    return tr_users, vd_users, te_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99168,) (12396,) (12396,)\n"
     ]
    }
   ],
   "source": [
    "unique_uid = user_activity.index\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "tr_users, vd_users, te_users = split_users(\n",
    "    unique_uid, test_users_size=0.1\n",
    ")\n",
    "print(tr_users.shape, vd_users.shape, te_users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how the authors set up the experiment: for validation and test they consider \"*only*\" items that have been seen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training observations raw data \n",
    "tr_obsrv = filtered_raw_data.loc[filtered_raw_data[\"user\"].isin(tr_users)]\n",
    "tr_items = pd.unique(tr_obsrv[\"item\"])\n",
    "\n",
    "# Save index dictionaries to \"numerise\" later one\n",
    "item2id = dict((sid, i) for (i, sid) in enumerate(tr_items))\n",
    "user2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "vd_obsrv = filtered_raw_data[\n",
    "    filtered_raw_data[\"user\"].isin(vd_users)\n",
    "    & filtered_raw_data[\"item\"].isin(tr_items)\n",
    "]\n",
    "\n",
    "te_obsrv = filtered_raw_data[\n",
    "    filtered_raw_data[\"user\"].isin(te_users)\n",
    "    & filtered_raw_data[\"item\"].isin(tr_items)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the validation and test users and their interactions, we will split such interactions into so-called \"*validation and test train and test sets*\". \n",
    "\n",
    "I know that this sounds convoluted, but is not that complex. The \"*validation_train and test_train sets*\", comprising here 80% of the total validation and test sets, will be used to build what we could think as an input binary *\"image\"* to be \"*encoded -> decoded*\" by the trained auto-encoder. On the other hand the \"*validation_test and test_test sets*\", comprising here 20% of the total validation and test sets, will be used to compute the ranking metrics at validation/test time. If you want more details along with a toy example please go to the corresponding [notebook](http://localhost:8790/notebooks/notebooks/01_prepare_data.ipynb) in the repo. I will discuss this further in Section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def split_train_test(\n",
    "    data: pd.DataFrame, test_size: float\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    data_grouped_by_user = data.groupby(\"user\")\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (nm, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype=\"bool\")\n",
    "            idx[\n",
    "                np.random.choice(\n",
    "                    n_items_u, size=int(test_size * n_items_u), replace=False\n",
    "                ).astype(\"int64\")\n",
    "            ] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "\n",
    "def numerize(tp: pd.DataFrame, user2id: Dict, item2id: Dict) -> pd.DataFrame:\n",
    "    user = [user2id[x] for x in tp[\"user\"]]\n",
    "    item = [item2id[x] for x in tp[\"item\"]]\n",
    "    return pd.DataFrame(data={\"user\": user, \"item\": item}, columns=[\"user\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_items_tr, vd_items_te = split_train_test(vd_obsrv, test_size=0.2)\n",
    "te_items_tr, te_items_te = split_train_test(te_obsrv, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 $\\text{Mult-VAE}^{\\text{PR}}$, the code\n",
    "\n",
    "After the explanation in Section 1 you might expect the code to look rather complex. However, you might feel disappointed/pleased when you see how simple it really is. \n",
    "\n",
    "In the [original publications](https://arxiv.org/pdf/1802.05814.pdf) the authors used a one hidden layer MLP as generative model. There they say that deeper architectures do not improve the results, which I find it to be true after having run over 120 experiments. With that it mind, let's first have a look the model $ I \\rightarrow 600 \\rightarrow 200 \\rightarrow 600 \\rightarrow I$, where $I$ is the total number of items: \n",
    "\n",
    "![](figures/mvae/multvae_arch.png)\n",
    "\n",
    "The colors in the Figure are my attempt to emphasize the *reparameterization trick*. \n",
    "\n",
    "In code, the figure above is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon import nn, HybridBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEEncoder(HybridBlock):\n",
    "    def __init__(self, q_dims: List[int], dropout: List[float]):\n",
    "        super().__init__()\n",
    "\n",
    "        # last dim multiplied by two for the reparameterization trick\n",
    "        q_dims_ = q_dims[:-1] + [q_dims[-1] * 2]\n",
    "        with self.name_scope():\n",
    "            self.q_layers = nn.HybridSequential(prefix=\"q_net\")\n",
    "            for p, inp, out in zip(dropout, q_dims_[:-1], q_dims_[1:]):\n",
    "                self.q_layers.add(nn.Dropout(p))\n",
    "                self.q_layers.add(nn.Dense(in_units=inp, units=out))\n",
    "\n",
    "    def hybrid_forward(self, F, X):\n",
    "        h = F.L2Normalization(X)\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu, logvar = F.split(h, axis=1, num_outputs=2)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(HybridBlock):\n",
    "    def __init__(self, p_dims: List[int], dropout: List[float]):\n",
    "        super().__init__()\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.p_layers = nn.HybridSequential(prefix=\"p_net\")\n",
    "            for p, inp, out in zip(dropout, p_dims[:-1], p_dims[1:]):\n",
    "                self.p_layers.add(nn.Dropout(p))\n",
    "                self.p_layers.add(nn.Dense(in_units=inp, units=out))\n",
    "\n",
    "    def hybrid_forward(self, F, X):\n",
    "        h = X\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(HybridBlock):\n",
    "    def __init__(\n",
    "        self,\n",
    "        p_dims: List[int],\n",
    "        dropout_enc: List[float],\n",
    "        dropout_dec: List[float],\n",
    "        q_dims: List[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encode = VAEEncoder(q_dims, dropout_enc)\n",
    "        self.decode = Decoder(p_dims, dropout_dec)\n",
    "\n",
    "    def hybrid_forward(self, F, X):\n",
    "        mu, logvar = self.encode(X)\n",
    "        std = F.exp(0.5 * logvar)\n",
    "        eps = F.random.normal_like(std)\n",
    "        sampled_z = mu + autograd.is_training() * eps * std\n",
    "        return self.decode(sampled_z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move on, let me mention (and appreciate) one of the many nice \"little\" things that `Mxnet`'s `Gluon` has to offer. You will notice the use of `HybridBlock` and the use of the input `F` (the backend) when we define the forward pass, or more precisely, the `hybrid_forward` pass. One could write a full post on the joys of `HybridBlocks` and how nicely and easily the guys that developed `Gluon` brought together the flexibility of imperative frameworks (i.e. `Pytorch`) and the speed of declarative frameworks (i.e. `Tensorflow`) together. If you want to learn the details go [here](https://gluon.mxnet.io/chapter07_distributed-learning/hybridize.html), but believe me, this is **FAST**. \n",
    "\n",
    "Having said that, there is only one more piece that we need to have the complete model, the loss function in Eq (12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_fn(inp, out, mu, logvar, anneal):\n",
    "    # firt term\n",
    "    neg_ll = -nd.mean(nd.sum(nd.log_softmax(out) * inp, -1))\n",
    "    # second term without beta\n",
    "    KLD = -0.5 * nd.mean(nd.sum(1 + logvar - nd.power(mu, 2) - nd.exp(logvar), axis=1))\n",
    "    # \"full\" loss\n",
    "    return neg_ll + beta * KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [paper](https://arxiv.org/pdf/1802.05814.pdf) the authors also use a Multinomial Denoising Autoencoder (Mult-DAE). The architecture is identical to that of the $\\text{Mult-VAE}^{\\text{PR}}$ apart from the fact that there is no variational aspect. I have implemented the Mult-DAE and run multiple experiments with it. However, given its simplicity and an already lengthy post, I will not discuss the corresponding code here. \n",
    "\n",
    "Let's have a look to the `MultiVAE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 50000\n",
    "q_dims = [I] + [600, 200]\n",
    "p_dims = [200, 600] + [I]\n",
    "dropout_enc = [0.5, 0.]\n",
    "dropout_dec = [0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiVAE(\n",
       "  (encode): VAEEncoder(\n",
       "    (q_layers): HybridSequential(\n",
       "      (0): Dropout(p = 0.5, axes=())\n",
       "      (1): Dense(50000 -> 600, linear)\n",
       "      (2): Dropout(p = 0.0, axes=())\n",
       "      (3): Dense(600 -> 400, linear)\n",
       "    )\n",
       "  )\n",
       "  (decode): Decoder(\n",
       "    (p_layers): HybridSequential(\n",
       "      (0): Dropout(p = 0.0, axes=())\n",
       "      (1): Dense(200 -> 600, linear)\n",
       "      (2): Dropout(p = 0.0, axes=())\n",
       "      (3): Dense(600 -> 50000, linear)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model = MultiVAE(\n",
    "    p_dims=p_dims,\n",
    "    q_dims=q_dims,\n",
    "    dropout_enc=dropout_enc,\n",
    "    dropout_dec=dropout_dec,\n",
    ")\n",
    "vae_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Future Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
